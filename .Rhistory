View(articles_text)
bigrams <- articles_text %>% mutate(sentence= str_squish(sentence)) |>
mutate(text = tolower(sentence)) |>
mutate(text = gsub("\\d+", "", text)) |>
mutate(text = str_replace_all(text, "raymond", "")) %>%
mutate(text = str_replace_all(text, "newsweek", "")) %>%
mutate(text = str_replace_all(text, "image", "")) %>%
mutate(text = str_replace_all(text, "perspective", "")) %>%
mutate(text = str_replace_all(text, "registered u.s. patent office", "")) %>%
mutate(text = str_replace_all(text, "- ", "")) %>%
mutate(text = str_replace_all(text, " -", "")) %>%
mutate(text = str_replace_all(text, " - ", "")) %>%
unnest_tokens(word, text, token="ngrams", n=2 ) %>%
filter(!word %in% stop_words$word) %>%
filter(!word == "minor inaccuracies") %>%
filter(!word == "text extraction") %>%
filter(!word == "text version") %>%
filter(!is.na(word))
bigrams <- bigrams %>%
select(word, date, year, filename)
bigrams_separated <- bigrams %>%
separate(word, c("word1", "word2"), sep = " ")
#bigrams with stop words filtered
bigrams_filtered <-
bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
bigram_counts <- bigrams_filtered %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
top_20_bigrams <- bigram_counts |>
top_n(20) |>
mutate(bigram = paste(word1, " ", word2)) |>
select(bigram, n)
datatable(bigram_counts,
caption = "Top Bigrams",
options = list(pageLength = 20))
top_20_bigrams <- bigram_counts |>
top_n(20) |>
mutate(bigram = paste(word1, " ", word2)) |>
select(bigram, n)
ggplot(top_20_bigrams, aes(n, bigram, fill=n)) +
geom_bar(stat="identity", position="dodge") +
labs(title = "Twenty Most Common Two-Word Phrases in Articles By Raymond Moley, 1937-1967",
x = "Count Across All Articles",
y = "Two-Word Phrase")
ggplot(top_20_bigrams, aes(n, reorder(bigram, n), fill=n)) +
geom_bar(stat="identity", position="dodge") +
labs(title = "Twenty Most Common Two-Word Phrases in Articles By Raymond Moley, 1937-1967",
x = "Count Across All Articles",
y = "Two-Word Phrase")
ggplot(top_20_bigrams, aes(n, reorder(bigram, n), fill=n)) +
geom_bar(stat="identity", position="dodge") +
theme(legend.position="none") +
labs(title = "Raymond Moley Common Phrases, 1937-1967",
x = "Count",
y = "Bigrams")
ggplot(top_20_bigrams, aes(n, reorder(bigram, n), fill=n)) +
geom_bar(stat="identity", position="dodge") +
theme(legend.position="none") +
geom_text(aes(label=n), hjust=-0.2) +
labs(title = "Raymond Moley Common Phrases, 1937-1967",
x = "Count",
y = "Bigrams")
ggplot(top_20_bigrams, aes(n, reorder(bigram, n), fill=n)) +
geom_bar(stat="identity", position="dodge") +
theme(legend.position="none") +
geom_text(aes(label=n), hjust=-0.2, size=2) +
labs(title = "Raymond Moley Common Phrases, 1937-1967",
x = "Count",
y = "Bigrams")
ggplot(top_20_bigrams, aes(n, reorder(bigram, n), fill=n)) +
geom_bar(stat="identity", position="dodge") +
theme(legend.position="none") +
geom_text(aes(label=n), hjust=-0.2, size=3) +
labs(title = "Raymond Moley Common Phrases, 1937-1967",
x = "Count",
y = "Bigrams")
articles <- articles_text |>
distinct(filename) |>
count()
View(articles)
nrows1 <- nrow(articles_text)
ncols1 <- ncol(articles_text)
articles <- articles_text |>
distinct(filename) |>
count()
nrows <- nrow(article_index)
ncols <- ncol(article_index)
nrows1 <- nrow(articles_text)
ncols1 <- ncol(articles_text)
articles <- articles_text |>
distinct(filename) |>
count()
glue::glue("The number of rows in the article text dataframe is {nrows1}")
glue::glue("The number of article text columns is {ncols1}")
glue::glue("The article text has {articles} articles. That's less than the {nrows} entries in the article index. The difference was due to about 70 failed AI scans.")
glue::glue("The article text has {articles} articles. That's less than the {nrows} entries in the article index. The difference was due to about {articles - nows} failed AI scans.")
glue::glue("The article text has {articles} articles. That's less than the {nrows} entries in the article index. The difference was due to about {articles - nrows} failed AI scans.")
1562-1487
glue::glue("The article text has {articles} articles. That's less than the {nrows} entries in the article index. The difference was due to about {nrows-articles} failed AI scans.")
ggplot(top_20_bigrams, aes(n, reorder(bigram, n), fill=n)) +
geom_bar(stat="identity", position="dodge") +
theme(legend.position="none") +
geom_text(aes(label=n), hjust=-0.2, size=3) +
labs(title = "Raymond Moley Common Phrases, 1937-1967",
subtitle = "Analysis of 1,487 Newsweek columns",
x = "Count",
y = "Bigrams",
caption = "Source: Newsweek. Graphic by Rob Wells and Bridget Lang, 2-14-2024")
count_year <- articles_text %>%
count(year) %>%
group_by(year) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
scale_x_continuous(labels = c(seq(1935, 1970, 5))) +
labs(title = "Moley Newsweek Columns By Year, 1937-1967",
subtitle = "Extracted Text Only",
caption = "n=1,487  articles. Graphic by Rob Wells, 2/14/2025",
y="Count of Pages",
x="Year")
count_year
articles_text %>%
count(year)
articles_text %>%
count(year) %>%
group_by(year)
articles_text %>%
distinct(filename) |>
count(year)
articles_text %>%
distinct(filename, .keep_all = TRUE) |>
count(year)
articles_text %>%
distinct(filename, .keep_all = TRUE) |>
count(year) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
scale_x_continuous(labels = c(seq(1935, 1970, 5))) +
labs(title = "Moley Newsweek Columns By Year, 1937-1967",
subtitle = "Extracted Text Only",
caption = "n=1,487  articles. Graphic by Rob Wells, 2/14/2025",
y="Count of Pages",
x="Year")
articles_text %>%
distinct(filename, .keep_all = TRUE) |>
count(year)
articles_text %>%
distinct(filename, .keep_all = TRUE) |>
count(year) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none")
articles_text %>%
distinct(filename, .keep_all = TRUE) |>
count(year) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
scale_x_continuous(breaks = seq(min(year), max(year), by = 5))+
labs(title = "Moley Newsweek Columns By Year, 1937-1967",
subtitle = "Extracted Text Only",
caption = "n=1,487  articles. Graphic by Rob Wells, 2/14/2025",
y="Count of Pages",
x="Year")
articles_text %>%
distinct(filename, .keep_all = TRUE) |>
count(year) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
scale_x_continuous(breaks = seq(1935, 1970, by = 5))+
labs(title = "Moley Newsweek Columns By Year, 1937-1967",
subtitle = "Extracted Text Only",
caption = "n=1,487  articles. Graphic by Rob Wells, 2/14/2025",
y="Count of Pages",
x="Year")
library(textdata)
library(tidyverse)
library(pdftools)
library(dplyr)
library(rio)
library(tidytext)
library(quanteda)
library(knitr)
library(formattable)
library(forcats)
library(readtext)
#topic modeling
library(tm)
library(topicmodels)
library(lda)
library(ldatuning)
# from tutorial packages
library(DT)
library(knitr)
library(kableExtra)
library(reshape2)
library(ggplot2)
library(wordcloud)
library(pals)
library(SnowballC)
library(flextable)
library(janitor)
#1562 articles in index
article_index <-  rio::import("matching with extract-Perspective_full_index_1967_1937.xls") |>
clean_names() |>
mutate(year = as.numeric(year),
date = as.Date(pubdate, format="%b %d, %Y"))
#136596 rows of text
articles_text <-  read_csv("/Users/gizmofo/Library/CloudStorage/Dropbox/Current_Projects/Moley project 2024/moley_cleaned_perspective_text.csv") |>
mutate(year = as.numeric(year),
date = as.Date(pubdate, format="%b %d, %Y"))
nrows <- nrow(article_index)
ncols <- ncol(article_index)
mean_year <- round(mean(article_index$year, na.rm = TRUE),0)
min_year <- min(article_index$year)
max_year <- max(article_index$year)
year_counts <-
article_index %>%
count(year)
max_count <- max(year_counts$n)
max_years <- year_counts %>%
select(year) %>%
filter(year_counts$n == max_count)
glue::glue("There are {nrows} articles in the index of Moley Newsweek columns.");
glue::glue("The earliest year of publication is {as.integer(min_year)}, and the latest is {max_year}.")
glue::glue("The average year of publication is {as.integer(mean_year)}, with the majority of articles written in {max_years$year}.")
nrows1 <- nrow(articles_text)
ncols1 <- ncol(articles_text)
articles <- articles_text |>
distinct(filename) |>
count()
glue::glue("The article text has {articles} articles. That's less than the {nrows} entries in the article index. The difference was due to about {nrows-articles} failed AI scans.")
glue::glue("The article text dataframe is huge, with {nrows1} rows and {ncols1} columns.")
nixon_articles <- articles_text %>%
filter(str_detect(sentence, "Nixon")) %>%
select(filename, year) %>%
distinct(filename, year)
goldwater_articles <- articles_text %>%
filter(str_detect(sentence, "Goldwater")) %>%
select(filename, year) %>%
distinct(filename, year)
roosevelt_articles <- articles_text %>%
filter(str_detect(sentence, "Roosevelt")) %>%
select(filename, year) %>%
distinct(filename, year)
dewey_articles <- articles_text %>%
filter(str_detect(sentence, "Dewey")) %>%
select(filename, year) %>%
distinct(filename, year)
nrc_sentiments <- get_sentiments("nrc")
afinn_sentiments <- get_sentiments("afinn")
View(nixon_articles)
nixon_articles2 <- articles_text %>%
group_by(filename, year) %>%
summarize(nixon_mentions = sum(str_detect(sentence, "Nixon"))) %>%
filter(nixon_mentions >= 2)
View(nixon_articles2)
head(articles_text)
nixon_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year) %>%
summarize(nixon_mentions = sum(str_detect(sentence, "Nixon"), na.rm = TRUE)) %>%
filter(nixon_mentions >= 2)
View(nixon_articles2)
test_mentions <- articles_text %>%
filter(!is.na(sentence)) %>%
filter(str_detect(sentence, "Nixon"))
print(paste("Total number of sentences mentioning Nixon:", nrow(test_mentions)))
View(nixon_articles)
goldwater_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year) %>%
summarize(goldwater_mentions = sum(str_detect(sentence, "Goldwater"), na.rm = TRUE)) %>%
filter(goldwater_mentions >= 2)
# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
goldwater_mentions <- articles_text %>%
filter(!is.na(sentence)) %>%
filter(str_detect(sentence, "Goldwater"))
print(paste("Total number of sentences mentioning Goldwater:", nrow(goldwater_mentions)))
print(paste("Total number of sentences mentioning Nixon:", nrow(nixon_mentions)))
print(paste("Total number of sentences mentioning Nixon:", nrow(nixon_mentions)))
nixon_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year) %>%
summarize(nixon_mentions = sum(str_detect(sentence, "Nixon"), na.rm = TRUE)) %>%
filter(nixon_mentions >= 2)
# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
nixon_mentions <- articles_text %>%
filter(!is.na(sentence)) %>%
filter(str_detect(sentence, "Nixon"))
print(paste("Total number of sentences mentioning Nixon:", nrow(nixon_mentions)))
roosevelt_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year) %>%
summarize(roosevelt_mentions = sum(str_detect(sentence, "Roosevelt"), na.rm = TRUE)) %>%
filter(roosevelt_mentions >= 2)
# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
roosevelt_mentions <- articles_text %>%
filter(!is.na(sentence)) %>%
filter(str_detect(sentence, "Roosevelt"))
print(paste("Total number of sentences mentioning Roosevelt:", nrow(roosevelt_mentions)))
View(roosevelt_articles2)
dewey_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year) %>%
summarize(dewey_mentions = sum(str_detect(sentence, "Dewey"), na.rm = TRUE)) %>%
filter(dewey_mentions >= 2)
# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
dewey_mentions <- articles_text %>%
filter(!is.na(sentence)) %>%
filter(str_detect(sentence, "Dewey"))
print(paste("Total number of sentences mentioning dewey:", nrow(dewey_mentions)))
View(dewey_articles2)
names(articles_text)
nixon_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year, date) %>%
summarize(nixon_mentions = sum(str_detect(sentence, "Nixon"), na.rm = TRUE)) %>%
filter(nixon_mentions >= 2)
View(nixon_articles2)
goldwater_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year, date) %>%
summarize(roosevelt_mentions = sum(str_detect(sentence, "Goldwater"), na.rm = TRUE)) %>%
filter(goldwater_mentions >= 2)
goldwater_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year, date) %>%
summarize(goldwater_mentions = sum(str_detect(sentence, "Goldwater"), na.rm = TRUE)) %>%
filter(goldwater_mentions >= 2)
# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
goldwater_mentions <- articles_text %>%
filter(!is.na(sentence)) %>%
filter(str_detect(sentence, "Goldwater"))
print(paste("Total number of sentences mentioning Goldwater:", nrow(goldwater_mentions)))
roosevelt_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year, date) %>%
summarize(roosevelt_mentions = sum(str_detect(sentence, "Roosevelt"), na.rm = TRUE)) %>%
filter(roosevelt_mentions >= 2)
# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
roosevelt_mentions <- articles_text %>%
filter(!is.na(sentence)) %>%
filter(str_detect(sentence, "Roosevelt"))
print(paste("Total number of sentences mentioning Roosevelt:", nrow(roosevelt_mentions)))
dewey_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year, date) %>%
summarize(dewey_mentions = sum(str_detect(sentence, "Dewey"), na.rm = TRUE)) %>%
filter(dewey_mentions >= 2)
# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
dewey_mentions <- articles_text %>%
filter(!is.na(sentence)) %>%
filter(str_detect(sentence, "Dewey"))
print(paste("Total number of sentences mentioning dewey:", nrow(dewey_mentions)))
politicians <- rbind(nixon_articles2, goldwater_articles2)
View(politicians)
politicians <- rbind(nixon_articles2, goldwater_articles2, roosevelt_articles2, dewey_articles2)
View(politicians)
nixon_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year, date) %>%
summarize(mentions = sum(str_detect(sentence, "Nixon"), na.rm = TRUE)) %>%
filter(mentions >= 2) |>
mutate(politician = "Nixon")
goldwater_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year, date) %>%
summarize(mentions = sum(str_detect(sentence, "Goldwater"), na.rm = TRUE)) %>%
filter(mentions >= 2) |>
mutate(politician = "Goldwater")
roosevelt_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year, date) %>%
summarize(mentions = sum(str_detect(sentence, "Roosevelt"), na.rm = TRUE)) %>%
filter(mentions >= 2) |>
mutate(politician = "Roosevelt")
dewey_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year, date) %>%
summarize(mentions = sum(str_detect(sentence, "Dewey"), na.rm = TRUE)) %>%
filter(mentions >= 2) |>
mutate(politician = "Dewey")
politicians <- rbind(nixon_articles2, goldwater_articles2, roosevelt_articles2, dewey_articles2)
View(politicians)
head(politicians)
ggplot(politicians, aes(y=mentions, x= year, fill=politician)) +
geom_bar(stat="identity", position="dodge") +
labs(title = "Sentiment of Thomas Dewey Articles",
x = "Sentiment",
y = "Percentage of Total Text",
caption = "Newsweek articles, Graphic by Rob Wells and Bridget Lang") +
theme(axis.text.x = element_text(angle = 45, vjust=0.5),legend.position = "none")
ggplot(politicians, aes(y=mentions, x= year, fill=politician)) +
geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1937, 1967, by = 2))+
labs(title = "Sentiment of Thomas Dewey Articles",
x = "Sentiment",
y = "Percentage of Total Text",
caption = "Newsweek articles, Graphic by Rob Wells and Bridget Lang") +
theme(axis.text.x = element_text(angle = 45, vjust=0.5))
ggplot(politicians, aes(y=mentions, x= year, fill=politician)) +
geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1937, 1967, by = 2))+
labs(title = "Moley's Coverage of Major Candidates",
subtitle = "Two or more mentions of politician in Newsweek",
y = "Count of Politician Mentions",
caption = "Newsweek articles, Graphic by Rob Wells") +
theme(axis.text.x = element_text(angle = 45, vjust=0.5))
ggplot(politicians, aes(y=mentions, x= year, fill=politician)) +
geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1937, 1967, by = 2))+
labs(title = "Moley's Coverage of Major Candidates",
subtitle = "Two or more mentions of politician in Newsweek",
y = "Count of Politician Mentions",
x = "",
caption = "Newsweek articles, Graphic by Rob Wells") +
theme(axis.text.x = element_text(angle = 45, vjust=0.5))
ggplot(politicians, aes(y=mentions, x= year, fill=politician)) +
geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1937, 1967, by = 2))+
labs(title = "Moley's Coverage of Major Candidates",
subtitle = "Two or more mentions of politician in Newsweek",
y = "Count of Politician Mentions",
x = "",
caption = "n=1,487 Newsweek articles, Graphic by Rob Wells") +
theme(axis.text.x = element_text(angle = 45, vjust=0.5))
ggplot(politicians, aes(y=mentions, x= year, fill=politician)) +
geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1936, 1968, by = 2))+
labs(title = "Moley's Coverage of Major Candidates",
subtitle = "Two or more mentions of politician in Newsweek",
y = "Count of Politician Mentions",
x = "",
caption = "n=1,487 Newsweek articles, Graphic by Rob Wells") +
theme(axis.text.x = element_text(angle = 45, vjust=0.5))
politicians |>
group_by(year) |>
summarize(sum(mentions))
politicians |>
group_by(year, politician) |>
summarize(total = sum(mentions))
politicians |>
group_by(year, politician) |>
summarize(total = sum(mentions))
ggplot(politicians, aes(y=total, x= year, fill=politician)) +
geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1936, 1968, by = 2))+
labs(title = "Moley's Coverage of Major Candidates",
subtitle = "Two or more mentions of politician in Newsweek",
y = "Count of Politician Mentions",
x = "",
caption = "n=1,487 Newsweek articles, Graphic by Rob Wells") +
theme(axis.text.x = element_text(angle = 45, vjust=0.5))
politicians |>
group_by(year, politician) |>
summarize(total = sum(mentions)) |>
ggplot(aes(y=total, x= year, fill=politician)) +
geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1936, 1968, by = 2))+
labs(title = "Moley's Coverage of Major Candidates",
subtitle = "Two or more mentions of politician in Newsweek",
y = "Count of Politician Mentions",
x = "",
caption = "n=1,487 Newsweek articles, Graphic by Rob Wells") +
theme(axis.text.x = element_text(angle = 45, vjust=0.5))
eisenhower_articles2 <- articles_text %>%
filter(!is.na(sentence)) %>%
group_by(filename, year, date) %>%
summarize(mentions = sum(str_detect(sentence, "Eisenhower"), na.rm = TRUE)) %>%
filter(mentions >= 2) |>
mutate(politician = "Eisenhower")
# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
eisenhower_mentions <- articles_text %>%
filter(!is.na(sentence)) %>%
filter(str_detect(sentence, "Eisenhower"))
print(paste("Total number of sentences mentioning eisenhower:", nrow(eisenhower_mentions)))
politicians <- rbind(nixon_articles2, goldwater_articles2, roosevelt_articles2, dewey_articles2, eisenhower_articles2)
politicians |>
group_by(year, politician) |>
summarize(total = sum(mentions)) |>
ggplot(aes(y=total, x= year, fill=politician)) +
geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1936, 1968, by = 2))+
labs(title = "Moley's Coverage of Major Candidates",
subtitle = "Two or more mentions of politician in Newsweek",
y = "Count of Politician Mentions",
x = "",
caption = "n=1,487 Newsweek articles, Graphic by Rob Wells") +
theme(axis.text.x = element_text(angle = 45, vjust=0.5))
write.csv(politicians, "../data/politicians_mentions_feb21.csv")
write.csv(politicians, ("../data/politicians_mentions_feb21.csv")
write.csv(politicians, ("../data/politicians_mentions_feb21.csv")
write.csv(politicians, "../data/politicians_mentions_feb21.csv")
write.csv(politicians, "politicians_mentions_feb21.csv")
