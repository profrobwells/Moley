subtitle = "Count of Lynching Stories Examined",
caption = "n=321,114  articles. Peak page count: 1903: 482 pages. Graphic by (redacted - peer review), 1/2/2025",
y="Count of Pages",
x="Year")
#Here is a chart, Figure 1, that describes lynching search results by year, counting news pages with at least one lynching story in the LOC database.
df %>%
count(year) %>%
group_by(year) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
scale_x_continuous(labels = c(seq(1800, 1960, 10)), breaks = seq(1800, 1960, 10)) +
labs(title = "without metadata Lynching Coverage By Year, 1805-1963",
subtitle = "Count of Lynching Stories Examined",
caption = "n=321,114  articles. Peak page count: 1903: 482 pages. Graphic by (redacted - peer review), 1/2/2025",
y="Count of Pages",
x="Year")
df1 %>%
count(year) %>%
group_by(year) |>
arrange(desc(n))
df3 <- df1 |>
filter(!is.na(sn))
df1 %>%
count(state) %>%
arrange(desc(n))
df3 <- df |>
inner_join(clean_newspaper_list, by=c("sn"="lccn")) |>
distinct(date1, sn, newspaper_name, page, cleaned_article, article, edition, .keep_all= TRUE)
df3 |>
count(state) |>
arrange(desc(n))
df1 <- df |>
left_join(clean_newspaper_list, by=c("sn"="lccn")) |>
distinct(date1, sn, newspaper_name, page, cleaned_article, article, edition, .keep_all= TRUE)
df3 <- df1 |>
filter(!is.na(sn))
#write.csv(df1, "lynching_articles_2025.csv")
write.csv(df1, "lynching_articles_2025.csv")
df$article[4,]
df$article[4]
df$article[18]
df1 |>
count(matches)
df1 |>
count(matches) |>
arrange(desc(n))
df1 |>
count(matches) |>
arrange(n)
df1 |>
count(matches) |>
arrange(desc((n))
df1 |>
count(matches) |>
arrange(desc(n))
df3 |> df1 |>
mutate(count_match = count(matches))
df3 <- df1 |>
mutate(count_match = count(matches))
df3 <- df1 |>
mutate(count_matches = str_count(matches, "\\blynch\\b"))
View(df3)
df3 <- df1 |>
mutate(count_matches = str_count(matches, "lynch"))
df3 <- df1 |>
mutate(count_matches = str_count(matches, "\\blynch\\b"))
head(df1)
glimpse(df1)
df3 <- df1 |>
mutate(count_matches = lengths(matches))
df_cleaned <- df3 |>
filter(count_matches > 1)
View(df_cleaned)
df_cleaned %>%
count(year) %>%
group_by(year) |>
arrange(desc(n))
df_cleaned %>%
count(year) %>%
group_by(year) |>
arrange(desc(n))
#Here is a chart, Figure 1, that describes lynching search results by year, counting news pages with at least one lynching story in the LOC database.
df_cleaned %>%
count(year) %>%
group_by(year) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
scale_x_continuous(labels = c(seq(1800, 1960, 10)), breaks = seq(1800, 1960, 10)) +
labs(title = "Lynching Coverage By Year, 1805-1963",
subtitle = "Count of Lynching Stories Examined",
caption = "n=69,023  articles. Peak page count: 1922: 2294	pages. Graphic by (redacted - peer review), 1/2/2025",
y="Count of Pages",
x="Year")
#Here is a chart, Figure 1, that describes lynching search results by year, counting news pages with at least one lynching story in the LOC database.
df_cleaned %>%
count(year) %>%
group_by(year) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
scale_x_continuous(labels = c(seq(1800, 1960, 10)), breaks = seq(1800, 1960, 10)) +
labs(title = "Lynching Coverage By Year, 1818-1963",
subtitle = "Count of Lynching Stories Examined",
caption = "n=69,023  articles. Peak page count: 1922: 2294	pages. Graphic by (redacted - peer review), 1/2/2025",
y="Count of Pages",
x="Year")
#df$article[18]
df2s <- df_cleaned |>
filter(count_matches = 2)
#df$article[18]
df2s <- df_cleaned |>
filter(count_matches == 2)
View(df2s)
df2s$article[4]
df2s$article[3]
df2s$article[12]
df2s$article[14]
df3s <- df_cleaned |>
filter(count_matches == 3)
View(df3s)
df2s$article[1]
df2s$article[2]
df2s$article[3]
df2s$article[4]
df2s$article[3]
df3s$article[3]
df3s$article[2]
df3s$article[4]
df3s$article[6]
df3s$article[14]
regex_patterns <- c(
"lynchings?\\W+of\\W+(the\\W+)?((\\w+\\W+){1,2})?colored",
"(murderer|fiend|desperado|brute)\\W+((\\w+\\W+){1,2})?lynch(ed|es|ing)?(\\W+|$)",
"coloreds?\\W+((\\w+\\W+){1,2})?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)",
"lynchings?\\W+of\\W+(the\\W+)?((\\w+\\W+){1,2})?negro",
"mob\\W+((\\w+\\W+){1,2})?(hung|hang(ed|ings?|s)|lynch(ed|es|ing)?)",
"negro(e?s)?\\W+((\\w+\\W+){1,2})?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)"
)
# Combine patterns into a single regex
combined_pattern <- paste(regex_patterns, collapse = "|")
# Filter the dataframe
filtered_df <- df1 %>%
filter(str_detect(articles, combined_pattern))
filtered_df <- df1 %>%
filter(str_detect(article, combined_pattern))
View(filtered_df)
combined_pattern
regex_patterns <- c(
#Matches the word "lynching" or "lynchings" (the ? makes the "s" optional).
"lynchings?\\W+of\\W+(the\\W+)?((\\w+\\W+){1,2})?colored",
# Matches any one of the words "murderer", "fiend", "desperado", or "brute".
"(murderer|fiend|desperado|brute)\\W+((\\w+\\W+){1,2})?lynch(ed|es|ing)?(\\W+|$)",
#Matches "colored" or "coloreds". and lynch
"coloreds?\\W+((\\w+\\W+){1,2})?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)",
#Matches "lynching" or "lynchings" and negro
"lynchings?\\W+of\\W+(the\\W+)?((\\w+\\W+){1,2})?negro",
# Matches the word "mob" "hung" and lynch.
# "mob\\W+((\\w+\\W+){1,2})?(hung|hang(ed|ings?|s)|lynch(ed|es|ing)?)",
#negro was|were lynched
"negro(e?s)?\\W+((\\w+\\W+){1,2})?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)"
)
# Combine patterns into a single regex
combined_pattern <- paste(regex_patterns, collapse = "|")
# Filter the dataframe: 6393 articles
filtered_df <- df1 %>%
filter(str_detect(article, combined_pattern))
regex_patterns <- c(
#lynch or lynched or lynching within five words of negro or colored
"(negro|colored)(\\W+\\w+){0,5}\\W+lynch(ed|ing)?",
#Matches the word "lynching" or "lynchings" (the ? makes the "s" optional).
"lynchings?\\W+of\\W+(the\\W+)?((\\w+\\W+){1,2})?colored",
# Matches any one of the words "murderer", "fiend", "desperado", or "brute".
"(murderer|fiend|desperado|brute)\\W+((\\w+\\W+){1,2})?lynch(ed|es|ing)?(\\W+|$)",
#Matches "colored" or "coloreds". and lynch
"coloreds?\\W+((\\w+\\W+){1,2})?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)",
#Matches "lynching" or "lynchings" and negro
"lynchings?\\W+of\\W+(the\\W+)?((\\w+\\W+){1,2})?negro",
# Matches the word "mob" "hung" and lynch.
"mob\\W+((\\w+\\W+){1,2})?(hung|hang(ed|ings?|s)|lynch(ed|es|ing)?)",
#negro was|were lynched
"negro(e?s)?\\W+((\\w+\\W+){1,2})?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)"
)
# Combine patterns into a single regex
combined_pattern <- paste(regex_patterns, collapse = "|")
# Filter the dataframe: 6393 articles
filtered_df <- df1 %>%
filter(str_detect(article, combined_pattern))
regex_patterns <- c(
#"mob" or "crowd" appear within five words of "lynch," "hung," "strung up," or "swing."
"(mob|crowd)(\\W+\\w+){0,5}\\W+(lynch|hung|strung\\s+up|swing)",
#lynch or lynched or lynching within five words of negro or colored
"(negro|colored)(\\W+\\w+){0,5}\\W+lynch(ed|ing)?",
#Matches the word "lynching" or "lynchings" (the ? makes the "s" optional).
"lynchings?\\W+of\\W+(the\\W+)?((\\w+\\W+){1,2})?colored",
# Matches any one of the words "murderer", "fiend", "desperado", or "brute".
"(murderer|fiend|desperado|brute)\\W+((\\w+\\W+){1,2})?lynch(ed|es|ing)?(\\W+|$)",
#Matches "colored" or "coloreds". and lynch
"coloreds?\\W+((\\w+\\W+){1,2})?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)",
#Matches "lynching" or "lynchings" and negro
"lynchings?\\W+of\\W+(the\\W+)?((\\w+\\W+){1,2})?negro",
# Matches the word "mob" "hung" and lynch.
"mob\\W+((\\w+\\W+){1,2})?(hung|hang(ed|ings?|s)|lynch(ed|es|ing)?)",
#negro was|were lynched
"negro(e?s)?\\W+((\\w+\\W+){1,2})?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)"
)
# Combine patterns into a single regex
combined_pattern <- paste(regex_patterns, collapse = "|")
# Filter the dataframe: 7397 articles
filtered_df <- df1 %>%
filter(str_detect(article, combined_pattern))
#Here is a chart, Figure 1, that describes lynching search results by year, counting news pages with at least one lynching story in the LOC database.
filtered_df %>%
count(year) %>%
group_by(year) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
scale_x_continuous(labels = c(seq(1800, 1960, 10)), breaks = seq(1800, 1960, 10)) +
labs(title = "Lynching Coverage By Year, 1818-1963",
subtitle = "Count of Lynching Stories Examined",
caption = "n=9593  articles. Peak page count: xxx: xxx	pages. Graphic by (redacted - peer review), 1/2/2025",
y="Count of Pages",
x="Year")
filtered_df$article[1]
filtered_df$article[24]
filtered_df$article[9000]
regex_patterns <- c(
#rough justice or "vigilance committee" or "popular justice" or "frontier justice" or "extrajudicial punishment" or rough music" or "summary execution"
"(rough\\s+justice|vigilance\\s+committee|popular\\s+justice|frontier\\s+justice|extrajudicial\\s+punishment|rough\\s+music|summary\\s+execution)",
#"mob" or "crowd" appear within five words of "lynch," "hung," "strung up," or "swing."
"(mob|crowd)(\\W+\\w+){0,5}\\W+(lynch|hung|strung\\s+up|swing)",
#lynch or lynched or lynching within five words of negro or colored
"(negro|colored)(\\W+\\w+){0,5}\\W+lynch(ed|ing)?",
#Matches the word "lynching" or "lynchings" (the ? makes the "s" optional).
"lynchings?\\W+of\\W+(the\\W+)?((\\w+\\W+){1,2})?colored",
# Matches any one of the words "murderer", "fiend", "desperado", or "brute".
"(murderer|fiend|desperado|brute)\\W+((\\w+\\W+){1,2})?lynch(ed|es|ing)?(\\W+|$)",
#Matches "colored" or "coloreds". and lynch
"coloreds?\\W+((\\w+\\W+){1,2})?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)",
#Matches "lynching" or "lynchings" and negro
"lynchings?\\W+of\\W+(the\\W+)?((\\w+\\W+){1,2})?negro",
# Matches the word "mob" "hung" and lynch.
"mob\\W+((\\w+\\W+){1,2})?(hung|hang(ed|ings?|s)|lynch(ed|es|ing)?)",
#negro was|were lynched
"negro(e?s)?\\W+((\\w+\\W+){1,2})?((was|were)\\W+)?lynch(ed|es|ing)?(\\W+|$)"
)
# Combine patterns into a single regex
combined_pattern <- paste(regex_patterns, collapse = "|")
# Filter the dataframe: 9593 articles
filtered_df <- df1 %>%
filter(str_detect(article, combined_pattern))
#Here is a chart, Figure 1, that describes lynching search results by year, counting news pages with at least one lynching story in the LOC database.
filtered_df %>%
count(year) %>%
group_by(year) %>%
#Sandwich it onto a simple ggplot
ggplot(aes(x = year, y = n, fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
scale_x_continuous(labels = c(seq(1800, 1960, 10)), breaks = seq(1800, 1960, 10)) +
labs(title = "Lynching Coverage By Year, 1818-1963",
subtitle = "Count of Lynching Stories Examined",
caption = "n=9593  articles. Peak page count: xxx: xxx	pages. Graphic by (redacted - peer review), 1/2/2025",
y="Count of Pages",
x="Year")
write.csv(filtered_df, "lynching_filtered_2025.csv")
# Install and load required packages
#install.packages(c("pdftools", "stringr"))
#install.packages("qpdf")
library(pdftools)
library(stringr)
library(pdftools)
library(stringr)
library(qpdf)
split_newsweek_articles <- function(input_pdf, output_dir = "split_articles") {
# Create output directory if it doesn't exist
if (!dir.exists(output_dir)) {
dir.create(output_dir)
}
# Read PDF text by pages
pdf_text <- pdf_text(input_pdf)
total_pages <- length(pdf_text)
# Initialize variables
article_info <- list()
# Function to safely extract and clean title
extract_title <- function(text) {
# Look for text that appears between the start of the page and "Moley, Raymond"
title <- str_extract(text, "^.*?(?=\\nMoley, Raymond)")
if(is.na(title)) return("untitled")
# Clean the title
title <- str_trim(title)
title <- str_replace_all(title, "[^[:alnum:][:space:]]", "")
title <- str_replace_all(title, "\\s+", "_")
if(nchar(title) == 0) return("untitled")
return(title)
}
# Process pages in groups of 3
for(i in seq(1, total_pages, by = 3)) {
# Check if we have enough pages left for a complete article
if(i + 2 <= total_pages) {
# Get the title
title <- extract_title(pdf_text[i])
# Add article info
article_info[[length(article_info) + 1]] <- list(
title = title,
article_page = i + 1  # The actual article is the second page in each group
)
cat("Found article:", title, "on page", i + 1, "\n")
}
# Extract each article
for(i in seq_along(article_info)) {
# Create filename
filename <- paste0(article_info[[i]]$title, "_", i, ".pdf")
# Create full path
filepath <- file.path(output_dir, filename)
# Extract just the article page
tryCatch({
pdf_subset(
input_pdf,
filepath,
pages = article_info[[i]]$article_page
)
cat("Saved article:", filename, "\n")
}, error = function(e) {
cat("Error saving", filename, ":", conditionMessage(e), "\n")
})
}
cat("Processed", length(article_info), "articles\n")
}
# Usage example:
input_pdf <- "Perspective_401_800_copy.pdf"  # Replace with your actual path
split_newsweek_articles(input_pdf, "split_articles")
# Usage example:
# Install and load required packages
#install.packages(c("pdftools", "stringr"))
#install.packages("qpdf")
library(pdftools)
library(stringr)
library(pdftools)
library(stringr)
library(qpdf)
setwd("~/Code/Moley")
# Install and load required packages
#install.packages(c("pdftools", "stringr"))
#install.packages("qpdf")
library(pdftools)
library(stringr)
library(pdftools)
library(stringr)
library(qpdf)
split_newsweek_articles <- function(input_pdf, output_dir = "split_articles") {
# Create output directory if it doesn't exist
if (!dir.exists(output_dir)) {
dir.create(output_dir)
}
# Read PDF text by pages
pdf_text <- pdf_text(input_pdf)
total_pages <- length(pdf_text)
# Initialize variables
article_info <- list()
# Function to safely extract and clean title
extract_title <- function(text) {
# Look for text that appears between the start of the page and "Moley, Raymond"
title <- str_extract(text, "^.*?(?=\\nMoley, Raymond)")
if(is.na(title)) return("untitled")
# Clean the title
title <- str_trim(title)
title <- str_replace_all(title, "[^[:alnum:][:space:]]", "")
title <- str_replace_all(title, "\\s+", "_")
if(nchar(title) == 0) return("untitled")
return(title)
}
# Process pages in groups of 3
for(i in seq(1, total_pages, by = 3)) {
# Check if we have enough pages left for a complete article
if(i + 2 <= total_pages) {
# Get the title
title <- extract_title(pdf_text[i])
# Add article info
article_info[[length(article_info) + 1]] <- list(
title = title,
article_page = i + 1  # The actual article is the second page in each group
)
cat("Found article:", title, "on page", i + 1, "\n")
}
# Extract each article
for(i in seq_along(article_info)) {
# Create filename
filename <- paste0(article_info[[i]]$title, "_", i, ".pdf")
# Create full path
filepath <- file.path(output_dir, filename)
# Extract just the article page
tryCatch({
pdf_subset(
input_pdf,
filepath,
pages = article_info[[i]]$article_page
)
cat("Saved article:", filename, "\n")
}, error = function(e) {
cat("Error saving", filename, ":", conditionMessage(e), "\n")
})
}
cat("Processed", length(article_info), "articles\n")
}
# Usage example:
input_pdf <- "Perspective_800_1200_copy.pdf"  # Replace with your actual path
split_newsweek_articles(input_pdf, "split_articles")
# Usage example:
pdf_files <- list.files(pattern = ".\rename_copy\.pdf$")
pdf_files <- list.files(pattern = "\rename_copy\.pdf$")
pdf_files <- list.files(pattern = "rename_copy\.pdf$")
pdf_files <- list.files(pattern = "..\rename_copy\.pdf$")
# List all PDF files in the current directory
pdf_files <- list.files(pattern = "..\\\\rename_copy\\\\.pdf$")
pdf_files <- list.files("/rename_copy", pattern="*.pdf")
pdf_files <- list.files("/rename_copy/", pattern="*.pdf")
pdf_files
# List all PDF files in the current directory
pdf_files <- list.files("../rename_copy/", pattern="*.pdf")
getwd()
pdf_files <- list.files("../rename_copy/", pattern="\\*.pdf")
pdf_files <- list.files("../rename_copy/", pattern="\\*.pdf",  full.names = TRUE)
pdf_files <- list.files("./rename_copy/", pattern="\\*.pdf",  full.names = TRUE)
pdf_files <- list.files("/rename_copy/", pattern="\\*.pdf",  full.names = TRUE)
pdf_files <- list.files(path = "../rename_copy/",
pattern = "\\.pdf$",
full.names = TRUE)
# Print the files found to verify
print("Files found:")
print(pdf_files)
# Create new filenames
base_files <- basename(pdf_files)
new_names <- file.path(dirname(pdf_files[1]), paste0("untitled_", seq_along(pdf_files), ".pdf"))
# Rename the files
file.rename(from = pdf_files, to = new_names)
pdf_files <- list.files(path = "../rename_copy/",
pattern = "\\.pdf$",
full.names = TRUE)
# Print the files found to verify
print("Files found:")
print(pdf_files)
# Get the directory path from the first file
dir_path <- dirname(pdf_files[1])
# Create new filenames with the same path structure
new_names <- sprintf("%s/untitled_%d.pdf",
dir_path,
seq_along(pdf_files))
# Print both vectors to verify lengths match
print("Number of original files:", length(pdf_files))
# List PDF files in the directory
pdf_files <- list.files(path = "../rename_copy/",
pattern = "\\.pdf$",
full.names = TRUE)
# Print the files found to verify
cat("Files found:\n")
print(pdf_files)
# Get the directory path from the first file
dir_path <- dirname(pdf_files[1])
# Create new filenames with the same path structure
new_names <- sprintf("%s/untitled_%d.pdf",
dir_path,
seq_along(pdf_files))
# Print lengths to verify they match
cat("Number of original files:", length(pdf_files), "\n")
cat("Number of new names:", length(new_names), "\n")
# Print the renaming plan
data.frame(
From = pdf_files,
To = new_names
)
# Rename the files
file.rename(from = pdf_files, to = new_names)
# Verify the results
list.files(path = "../rename_copy/", pattern = "\\.pdf$")
# List PDF files in the directory - using pattern to match PDFs ending in numbers
pdf_files <- list.files(path = "../rename_copy",
pattern = ".*\\d+\\.pdf$",
full.names = TRUE)
# Extract just the numbers from the end of each filename
numbers <- gsub(".*?(\\d+)\\.pdf$", "\\1", basename(pdf_files))
# Create new filenames using the extracted numbers
dir_path <- dirname(pdf_files[1])
new_names <- file.path(dir_path, sprintf("untitled_%s.pdf", numbers))
# Print the renaming plan to verify
renaming_plan <- data.frame(
From = basename(pdf_files),
To = basename(new_names),
stringsAsFactors = FALSE
)
print(renaming_plan)
# Confirm with user
cat("Found", length(pdf_files), "PDF files to rename.\n")
cat("Type 'yes' to proceed with renaming: ")
answer <- readline()
if (tolower(answer) == "yes") {
# Rename the files
renamed <- file.rename(from = pdf_files, to = new_names)
# Check results
if (all(renamed)) {
cat("All files renamed successfully.\n")
} else {
cat("Some files could not be renamed.\n")
print(which(!renamed))
}
getwd()
