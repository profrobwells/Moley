{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profrobwells/Moley/blob/main/Moley_Newsweek_LAT_article_scan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Moley Article Text Extraction"
      ],
      "metadata": {
        "id": "nPIegirst1-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This Feb 8 2025 update of the Moley magazine article scan script"
      ],
      "metadata": {
        "id": "ookxZ9-1DmIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import time\n",
        "genai.configure(api_key=\"AIzaSyDEsLqLEo2vmpKoHQ-eEXBE0wHSrOXLKe4\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4n830vKBtzGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount my Google Drive at robwells21032 account"
      ],
      "metadata": {
        "id": "iXE6o2JgQ0u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#content is /content/drive/MyDrive/Moley_LAT"
      ],
      "metadata": {
        "id": "mcna2U5BiRy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "039b24ce-0291-4175-952c-b1c81255e46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to png and then scan"
      ],
      "metadata": {
        "id": "7GrHIyq7Mmcp"
      }
    },
    {
      "source": [
        "!apt-get install poppler-utils # Install poppler on Colab or similar Linux environments"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qzXw1iqWMfOt",
        "outputId": "46c637f9-b797-40e3-a902-f30cbf4cff42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
            "Fetched 186 kB in 1s (227 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126319 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install pdf2image  # Install pdf2image for PDF to image conversion\n",
        "\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "pdf_dir = '/content/drive/MyDrive/Moley_LAT/source'\n",
        "#pdf_dir = '/content/drive/MyDrive/Moley_LAT'  # Directory containing PDF files\n",
        "\n",
        "for filename in os.listdir(pdf_dir):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(pdf_dir, filename)  # Full path to PDF file\n",
        "        images = convert_from_path(pdf_path)  # Convert this specific PDF\n",
        "        for i, image in enumerate(images):\n",
        "            image.save(os.path.join(pdf_dir, f'{filename[:-4]}_page{i}.png'), 'PNG')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QL4NaVbQMHAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac0a820-3d6c-4cc2-cf14-87c7e95c5402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.2.1)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Text Extraction"
      ],
      "metadata": {
        "id": "W_VHla5rGCEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updated for LAT without messages"
      ],
      "metadata": {
        "id": "51j4_o2uHkR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import google.generativeai as genai\n",
        "# import time\n",
        "# genai.configure(api_key=\"YOUR_API_KEY\")\n",
        "\n",
        "# --- Main execution block ---\n",
        "# Define your input and output directories\n",
        "input_dir = \"/content/drive/MyDrive/Moley_LAT/source\"\n",
        "output_dir = \"/content/drive/MyDrive/Moley_LAT/june21_text\"\n",
        "\n",
        "# --- Functions ---\n",
        "\n",
        "def upload_to_gemini(path, mime_type=None):\n",
        "    \"\"\"Uploads a file to the Gemini API.\"\"\"\n",
        "    try:\n",
        "        file = genai.upload_file(path, mime_type=mime_type)\n",
        "        print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
        "        return file\n",
        "    except Exception as e:\n",
        "        # Catch potential exceptions like file not found, API errors, etc.\n",
        "        print(f\"Error uploading '{os.path.basename(path)}': {e}\")\n",
        "        return None\n",
        "\n",
        "def gemini_ocr(image_path, output_dir):\n",
        "    \"\"\"\n",
        "    Performs OCR on an image using Gemini Pro and saves the extracted text.\n",
        "    This version uses generate_content() for direct, non-conversational output.\n",
        "    \"\"\"\n",
        "    print(f\"Processing {os.path.basename(image_path)}...\")\n",
        "    try:\n",
        "        # 1. Set up model configuration\n",
        "        generation_config = {\n",
        "            \"temperature\": 0.5, # Lower temperature for more deterministic output\n",
        "            \"top_p\": 0.95,\n",
        "            \"top_k\": 40,\n",
        "            \"max_output_tokens\": 8192,\n",
        "            \"response_mime_type\": \"text/plain\",\n",
        "        }\n",
        "\n",
        "        model = genai.GenerativeModel(\n",
        "            #model_name=\"gemini-1.5-flash\",\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "\n",
        "        # 2. Upload the image file\n",
        "        uploaded_file = upload_to_gemini(image_path, mime_type=\"image/png\")\n",
        "        if not uploaded_file:\n",
        "            print(f\"Skipping {os.path.basename(image_path)} due to upload failure.\")\n",
        "            return\n",
        "\n",
        "        # 3. Create the prompt\n",
        "        # This prompt is clearer and more direct for the model.\n",
        "        prompt = \"\"\"Extract all text from the newspaper article in the provided image.\n",
        "The article may be in two or more columns. Ensure the text flows correctly from the bottom of one column to the top of the next. Do not merge sentences across columns.\n",
        "Your response must contain ONLY the extracted text and nothing else. Do not add any introductory phrases, summaries, or explanations.\"\"\"\n",
        "\n",
        "        # 4. Call the model with generate_content for a direct response\n",
        "        # This is the key change to prevent conversational replies.\n",
        "        response = model.generate_content([prompt, uploaded_file])\n",
        "\n",
        "        # Clean the response text by removing any accidental leading/trailing whitespace\n",
        "        extracted_text = response.text.strip()\n",
        "\n",
        "        # 5. Save the extracted text to a file\n",
        "        filename_without_ext = os.path.splitext(os.path.basename(image_path))[0]\n",
        "        output_path = os.path.join(output_dir, f\"{filename_without_ext}.txt\")\n",
        "\n",
        "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(extracted_text)\n",
        "\n",
        "        print(f\"Successfully saved text to {output_path}\")\n",
        "\n",
        "        # It's good practice to delete the file from the server after use\n",
        "        # to avoid accumulating files in your Gemini project.\n",
        "        genai.delete_file(uploaded_file.name)\n",
        "        print(f\"Deleted temporary file '{uploaded_file.display_name}' from server.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while processing {os.path.basename(image_path)}: {e}\")\n",
        "\n",
        "# --- Script Execution ---\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Get a list of all .png files in the input directory\n",
        "image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(\".png\")]\n",
        "print(f\"Found {len(image_files)} PNG files to process.\")\n",
        "\n",
        "if not image_files:\n",
        "    print(\"No PNG files found in the input directory. Please check the path.\")\n",
        "else:\n",
        "    for filename in image_files:\n",
        "        image_path = os.path.join(input_dir, filename)\n",
        "        gemini_ocr(image_path, output_dir)\n",
        "        # For the gemini-1.5-flash model the standard free limit is 15 Requests Per Minute (RPM).\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"\\nProcessing complete.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "H5idj9iKGE-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "N0TES ONLY --- BELOW\n",
        "OLDER CODE"
      ],
      "metadata": {
        "id": "NcoHnO9RQZPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loop for article extraction\n",
        "#in colab, first create a test and a text folder\n",
        "#\n",
        "# Weee!!!\n",
        "#\n",
        "#import os\n",
        "#import google.generativeai as genai\n",
        "#genai.configure(api_key=\"YOUR_API_KEY\")  # Replace with your actual API key\n",
        "import time\n",
        "def upload_to_gemini(path, mime_type=None):\n",
        "    \"\"\"Uploads a file to Gemini and returns its URI.\"\"\"\n",
        "    try:\n",
        "        file = genai.upload_file(path, mime_type=mime_type)\n",
        "        print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
        "        return file\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def gemini_ocr(image_path, output_dir):\n",
        "    \"\"\"Performs OCR on an image using Gemini and saves the output.\"\"\"\n",
        "    try:\n",
        "        generation_config = {\n",
        "            \"temperature\": 1,\n",
        "            \"top_p\": 0.95,\n",
        "            \"top_k\": 40,\n",
        "            \"max_output_tokens\": 8192,\n",
        "            \"response_mime_type\": \"text/plain\",\n",
        "        }\n",
        "\n",
        "        # Define the model within the function:\n",
        "        model = genai.GenerativeModel(\n",
        "            model_name=\"gemini-1.5-flash\",\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "\n",
        "        # Upload the image\n",
        "        uploaded_file = upload_to_gemini(image_path, mime_type=\"image/png\")\n",
        "        if uploaded_file is None:\n",
        "            return\n",
        "#instructions for LAT:  \"Take the uploaded png file which is a newspaper article, extract the text and headline. produce a .txt file with the same file name as the .pdf file. be careful because the article is in two or more columns so make sure the text file does not overlap text from column 1 and 2 and so forth. Do not provide any messages such as 'Here's the text extracted from the image:'Here's the text extracted from the image' or 'Here's the extracted text from the provided image.  I've attempted to maintain the original column structure as much as possible, but some minor adjustments might be needed for perfect accuracy'\",\n",
        "        chat_session = model.start_chat(\n",
        "            history=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"parts\": [\n",
        "                        uploaded_file,\n",
        "                         \"Take the uploaded png file which is a newspaper article, extract the text and headline. produce a .txt file with the same file name as the .pdf file. be careful because the article is in two or more columns so make sure the text file does not overlap text from column 1 and 2 and so forth. Do not provide any messages such as 'Here's the text extracted from the image:'Here's the text extracted from the image' or 'Here's the extracted text from the provided image.  I've attempted to maintain the original column structure as much as possible, but some minor adjustments might be needed for perfect accuracy'\",\n",
        "                    ],\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        response = chat_session.send_message(content=\"Please extract the text.\")\n",
        "        extracted_text = response.text\n",
        "\n",
        "        # Remove unwanted message:\n",
        "        unwanted_message = \"Here's the text extracted from the provided image. Note that some minor formatting inconsistencies might remain due to the image quality and the nature of OCR.\"\n",
        "        extracted_text = extracted_text.replace(unwanted_message, \"\").strip()  # Remove and strip whitespace\n",
        "\n",
        "\n",
        "        # Extract filename without extension\n",
        "        filename = os.path.splitext(os.path.basename(image_path))[0]\n",
        "        output_path = os.path.join(output_dir, f\"{filename}.txt\")\n",
        "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(extracted_text)\n",
        "        print(f\"Text extracted and saved to {output_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "\n",
        "#  --- Main execution block ---\n",
        "#input_dir = \"/content/drive/MyDrive/Moley_LAT\"  # Folder containing PNG images\n",
        "#output_dir = \"/content/drive/MyDrive/Moley_LAT/text\"  # Folder to store extracted text\n",
        "input_dir = \"/content/drive/MyDrive/Moley_LAT\"  # Folder containing PNG images\n",
        "output_dir = \"/content/drive/MyDrive/Moley_LAT/june20_text\"  # Folder to store extracted text\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Updated loop:\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith(\".png\"):\n",
        "        image_path = os.path.join(input_dir, filename)  # Construct image path\n",
        "        try:\n",
        "            gemini_ocr(image_path, output_dir)  # Call with image path\n",
        "            time.sleep(5)\n",
        "        except ValueError as e:\n",
        "            if \"content' argument must not be empty\" in str(e):\n",
        "                print(f\"Skipping {filename} due to empty content error.\")\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "print(\"Processing complete.\")\n"
      ],
      "metadata": {
        "id": "7qSh2IyF8QEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87fc94b6-dafc-4d80-a2ba-5fd3a942d260",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complete.\n"
          ]
        }
      ]
    }
  ]
}