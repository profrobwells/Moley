---
title: "Moley LAT Index"
output: html_notebook
---
This notebook processes the moley lat index

```{r}
library(tidyverse)
```
### Import data
```{r}

lat_index <- rio::import("./data/moley_lat.csv") |> 
  mutate(date = as.Date(entryDate, "%b %d, %Y")) |> 
  mutate(year2 = year(date))

```


### fact check all years match
```{r}
lat_index %>%
  mutate(years_match = year1 == year2) %>%
  summarise(all_match = all(years_match))

lat_index %>%
  filter(year1 != year2) %>%
  select(year1, year2)
```

### count of years
```{r}
counts <- lat_index |> 
  count(year1) 

sum(counts$n)
#2522 entries
```

### Moley full index
```{r}
full_index <- rio::import("./data/moley_lat_full_index.csv") |> 
  mutate(date = as.Date(PubDate, "%m/%d/%Y")) |> 
  mutate(year2 = year(date))
```


```{r}

counts_full <- full_index |> 
  count(year2) 
```

```{r}
anti <- counts |> 
  anti_join(counts_full)


```

#list actual downloaded files
```{r}
files_downloaded <- list.files("/Users/robwells/Library/CloudStorage/Dropbox/Current_Projects/Moley project 2024/Moley_LAT_column", pattern="*.pdf") %>% 
  as.data.frame() |> 
  rename(filename = 1) |> 
  mutate(filename1 = str_replace_all(filename, ".pdf", ""))
```

### modify lat_index to match properly. -- adding "_1" as suffix
```{r}
lat_index <- lat_index |> 
  mutate(filename1 = paste0(StoreId, "_1"))

```

```{r}
updated_lat_moley_index <- lat_index |> 
  inner_join(files_downloaded, by=c("filename1")) |> 
  select(date, entryDate, year1, Title, Abstract, StoreId, filename1,filename)  

write.csv(updated_lat_moley_index, "updated_lat_moley_index.csv")
```

## fact check
```{r}
anti <- files_downloaded |> 
  anti_join(lat_index, by=c("filename1"))

```

# OCR LAT stories
#Load Libraries
```{r}
library(pdftools)
library(tesseract)
library(magick)

```

#Loop Through PDFs in a Directory

```{r}
# Define paths
pdf_folder <- "./lat_sample"
extracted_folder <- "./lat_scanned"

# Create extracted folder if it doesn't exist
if (!dir.exists(extracted_folder)) {
  dir.create(extracted_folder)
}

# Loop through all files in the PDF folder
pdf_files <- list.files(pdf_folder, pattern = "\\.png$", full.names = TRUE)
for (pdf_file in pdf_files) {
  output_file <- file.path(extracted_folder, paste0(tools::file_path_sans_ext(basename(pdf_file)), ".txt"))
  pdf_text <- pdf_text(pdf_file)
  writeLines(pdf_text, output_file)
  cat("Text extracted from", pdf_file, "and saved to", output_file, "\n")
}

```

```{r}
library(pdftools)
library(tesseract)
library(magick)
# Define paths
pdf_folder <- "./lat_sample"
extracted_folder <- "./lat_scanned"

# Create extracted folder if it doesn't exist
if (!dir.exists(extracted_folder)) {
  dir.create(extracted_folder)
}

# Loop through all files in the PDF folder
pdf_files <- list.files(pdf_folder, pattern = "\\.png$", full.names = TRUE)
for (file_path in pdf_files) {
  # Construct the output path
  output_filename <- paste0(tools::file_path_sans_ext(basename(file_path)), ".txt")
  output_path <- file.path(extracted_folder, output_filename)
  
  # Check the file extension and process accordingly
  grepl("\\.png$", file_path) 
    # Extract text from PNG using tesseract
    text <- ocr(file_path)
    writeLines(text, output_path)
  
  
  cat("Text extracted from", basename(file_path), "and saved to", output_filename, "\n")
}

```

Pre-processing the images before OCR:

```{r}
library(magick)

# Function to pre-process images
preprocess_image <- function(file_path) {
  image <- image_read(file_path) %>%
    image_resize("3000x") %>%  # Increase resolution
    image_contrast(sharpen = 100) %>%  # Enhance contrast
    image_convert(colorspace = "gray") %>%  # Convert to grayscale
    image_deskew() %>%  # Correct skewing
    image_trim()  # Remove excess white space
  return(image)
}

# Modified loop
for (file_path in pdf_files) {
  output_filename <- paste0(tools::file_path_sans_ext(basename(file_path)), ".txt")
  output_path <- file.path(extracted_folder, output_filename)
  
  # Preprocess image
  processed_img <- preprocess_image(file_path)
  
  # Extract text with additional tesseract configuration
  text <- tesseract::ocr(processed_img, 
                        engine = tesseract(options = list(
                          tessedit_char_whitelist = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,;:'\"()-!? ",
                          preserve_interword_spaces = 1
                        )))
  
  # Basic text cleaning
  text <- gsub("\\s+", " ", text)  # Remove extra whitespace
  text <- gsub("-\\s+", "", text)  # Remove hyphenation at line breaks
  text <- gsub("([a-z])\\s+([A-Z])", "\\1\\2", text)  # Join split words
  
  writeLines(text, output_path)
  cat("Text extracted from", basename(file_path), "and saved to", output_filename, "\n")
}
```

Post-processing with string cleaning:
```{r}
library(stringr)

clean_ocr_text <- function(text) {
  text <- str_trim(text)  # Remove leading/trailing whitespace
  text <- gsub("\\s{2,}", " ", text)  # Remove multiple spaces
  text <- gsub("(?<=\\w)-\\s+(?=\\w)", "", text, perl = TRUE)  # Remove hyphenation
  text <- gsub("([a-z])\\s+([A-Z])", "\\1 \\2", text)  # Fix word spacing
  text <- gsub("\\b(\\w)\\s+(\\w{1,2})\\b", "\\1\\2", text)  # Join split short words
  text <- gsub("([^.!?])\\s*\\n\\s*([a-z])", "\\1 \\2", text)  # Fix sentence breaks
  text <- gsub("\\b(\\w)\\s+('s|'t|'d|'ll|'ve|'re)\\b", "\\1\\2", text)  # Fix contractions
  return(text)
}

# Apply to your existing loop:
text <- clean_ocr_text(text)
```

Consider using a different OCR engine configuration:
```{r}

# Try different tesseract configurations
eng <- tesseract(options = list(
  tessedit_pageseg_mode = 1,  # Automatic page segmentation with OSD
  tessedit_ocr_engine_mode = 3,  # Legacy + LSTM engines
  textord_heavy_nr = 1,  # Heavy noise removal
  language = "eng"
))

text <- tesseract::ocr(processed_img, engine = eng)
```


```{r}
# For column-based text
eng <- tesseract(options = list(
  tessedit_pageseg_mode = 1,  # Try different modes (1-13)
  textord_tablefind_recognize_tables = 0,
  textord_detect_columns = 1
))
```


# Notes below

```{r}
dupes <- updated_lat_moley_index |> 
  count(date, Title) |> 
  filter(n==2)

dupes <- dupes |> 
  inner_join(updated_lat_moley_index, by=c("date"))


```

```{r}
#This tutorial shows how to copy files from one directory to another
# https://stackoverflow.com/questions/68995687/r-move-files-to-folder-based-on-list-or-column

inputdir  <- "./lat_sample" 
targetdir <- "./renamed_lat" 
df <- updated_lat_moley_index$Title
filestocopy <- list.files(inputdir, full.names = TRUE)

filestocopy <- unique(grep(paste(df,collapse="|"), filestocopy, value=TRUE))

sapply(filestocopy, function(x) file.copy(from=x, to=targetdir, copy.mode = TRUE))
```


```{r}

```


