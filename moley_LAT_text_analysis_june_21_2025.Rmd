---
title: "Content Analysis of Raymond Moley’s Newspaper Column from 1937 - 1968"
author: "Rob Wells and Bridget Lang"
date: '2025-6-21'
output: html_document
---

This notebook performs a basic narrative and topic analysis of the syndicated newspaper column **Raymond Moley** wrote from 1942-1969 as published in the Los Angeles Times syndicate. 

The goal of this project is to **measure patterns in wording, verbiage, themes, and sentiment** of Raymond Moley's poltitical reporting over time. This research will support a larger effort in analyzing the **influence of journalism and polticial activism on American elections, voting, and democracy at large**. 

I am focusing on the time period of Moley's work from **1942-1969**, with **2,501 articles**  analyzed. 

The full index has 2547 articles

The average year of publication is xxx, with the majority of articles written in xxx.
The article text has 2501 articles. The difference of 46 articles was due to failed AI scans.

# Load Libraries
```{r message=FALSE, warning=FALSE, include=FALSE}


library(textdata)
library(tidyverse)
library(pdftools)
library(dplyr)
library(rio)
library(tidytext)
library(quanteda)
library(knitr)
library(formattable)
library(forcats)
library(readtext)
#topic modeling
library(tm)
library(topicmodels)
library(lda)
library(ldatuning)
# from tutorial packages
library(DT)
library(knitr) 
library(kableExtra) 
library(reshape2)
library(ggplot2)
library(wordcloud)
library(pals)
library(SnowballC)
library(flextable)
library(janitor)
```

## Load LAT Data
```{r echo = F}
#2501 articles in index
article_index <-  rio::import("./data/moley_lat_final_index_scanned_june_21.csv") |> 
  clean_names() |> 
  mutate(year = lubridate::year(date))
  

#284067 rows of text
articles_text <-  read_csv("/Users/gizmofo/Library/CloudStorage/Dropbox/Current_Projects/Moley project 2024/Indexes of Moley Articles/moley_lat_text_june_21.csv") |> 
   clean_names() |> 
    mutate(year = as.numeric(year))

#284067 rows of text
articles_text <-  read_csv("/Users/gizmofo/Library/CloudStorage/Dropbox/Current_Projects/Moley project 2024/Indexes of Moley Articles/lat_articles_text_update_7_23.csv") |>
   clean_names() |>
    mutate(year = as.numeric(year))

```
## Statistics about the index 
```{r}

nrows <- nrow(article_index)
ncols <- ncol(article_index)

mean_year <- round(mean(article_index$year, na.rm = TRUE),0)

min_year <- min(article_index$year)

max_year <- max(article_index$year)


year_counts <- 
  article_index |>
  count(year)

max_count <- max(year_counts$n)
max_years <- year_counts |>
  select(year) |>
  filter(year_counts$n == max_count)
                  

glue::glue("There are {nrows} articles in the index of Moley newspaper columns.");

glue::glue("The earliest year of publication is {as.integer(min_year)}, and the latest is {max_year}.")

glue::glue("The average year of publication is {as.integer(mean_year)}, with the majority of articles written in {max_years$year}.")




```

## Statistics about the extracted text
```{r echo = F}
nrows1 <- nrow(articles_text)
ncols1 <- ncol(articles_text)

articles <- articles_text |> 
  distinct(new_filename) |> 
  count()


glue::glue("The article text has {articles} articles. That matches the {nrows} entries in the article index. The difference was due to about {nrows-articles} failed AI scans.")
glue::glue("The article text dataframe is huge, with {nrows1} rows and {ncols1} columns.")

```


# Figure x: Articles over time

```{r}

#Here is a chart, Figure x, that counts columns by year
count_year <- articles_text |> 
  distinct(new_filename, .keep_all = TRUE) |> 
count(year) |> 
#Sandwich it onto a simple ggplot
  ggplot(aes(x = year, y = n, fill = n)) +
  geom_col(position = "dodge") + 
  theme(legend.position = "none") +
  scale_x_continuous(breaks = seq(1935, 1970, by = 5))+
  labs(title = "Moley Newspaper Columns By Year, 1942-1969", 
       subtitle = "Extracted Text Only",
       caption = "n=2,501  articles. Graphic by Rob Wells, 6/21/2025",
       y="Count of Pages",
       x="Year")

count_year

#ggsave(here::here("Figure_X_ columns_by_year_2_14_2025.png"),device = "png",width=9,height=6, dpi=800)

```


### Checking Narratives
# Bigrams
```{r}
bigrams <- articles_text |> mutate(sentence= str_squish(sentence)) |> 
  mutate(text = tolower(sentence)) |>  
  mutate(text = gsub("\\d+", "", text)) |>
  mutate(text = str_replace_all(text, "raymond", "")) |>
  mutate(text = str_replace_all(text, "newsweek", "")) |>
  mutate(text = str_replace_all(text, "image", "")) |>
  mutate(text = str_replace_all(text, "perspective", "")) |>
  mutate(text = str_replace_all(text, "registered u.s. patent office", "")) |>
  mutate(text = str_replace_all(text, "reproduced with permission of the copyright owner", "")) |>
  mutate(text = str_replace_all(text, "further reproduction prohibited without permission", "")) |>
  mutate(text = str_replace_all(text, "copyright", "")) |>
  mutate(text = str_replace_all(text, "new york city", "")) |>
  mutate(text = str_replace_all(text, "- ", "")) |>
  mutate(text = str_replace_all(text, " -", "")) |>
  mutate(text = str_replace_all(text, " - ", "")) |>
  unnest_tokens(word, text, token="ngrams", n=2 ) |>
  filter(!word %in% stop_words$word) |>
  filter(!word == "minor inaccuracies") |>
  filter(!word == "text extraction") |>
  filter(!word == "text version") |>
  filter(!word == "copyright owner") |>
  filter(!word == "reproduction prohibited") |>
  filter(!is.na(word))

bigrams <- bigrams |>
  select(word, date, year, new_filename)

```
#### Statism
```{r}
statism <- bigrams |> 
 filter(str_detect(word, "statism"))

statism |> 
  group_by(year) |> 
  count() |> 
ggplot(aes(x= year, y=n, fill=n)) +
  geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1941, 1964, by = 1)) +
  theme(legend.position="none",
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_text(aes(label=n), vjust = -.5, size=3) +
  labs(title = "'Statism' in Raymond Moley Newspaper Articles, 1937-1967",
       subtitle = "Analysis of 2,501 Newspaper columns",
       x = "Year",
       y = "Frequency",
       caption = "Source: Newspaper. Graphic by Rob Wells, 6-19-2025")

# ggsave("output/statism_Newspaper_6-19_2025.png", device = "png", width = 9, height = 6, dpi = 800)

```

#### Free Enterprise
```{r}
free <- c("private enterprise", "free enterprise",
"business enterprise", "individual enterprise", "enterprise system", "business enterprises",
"industrial enterprises")

enterprise <- bigrams |> 
 filter(str_detect(word, paste(free, collapse = "|")))



# enterprise |> 
#   count(word) |> 
#   arrange(desc(n))


enterprise |> 
  group_by(year) |> 
  count() |> 
ggplot(aes(x= year, y=n, fill=n)) +
  geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1937, 1966, by = 1)) +
  theme(legend.position="none",
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_text(aes(label=n), vjust = -.5, size=3) +
  labs(title = "Free Enterprise in Raymond Moley Newspaper Articles, 1937-1967",
       subtitle = "Analysis of 2,501 Newspaper columns",
       x = "Year",
       y = "Frequency",
       caption = "Free enterprise and six variants of phrase. Source: Newspaper. Graphic by Rob Wells, 6-19-2025")

# ggsave("output/free_enterprise_Newspaper_6-19_2025.png", device = "png", width = 9, height = 6, dpi = 800)

```

#### Communism
```{r}
free <- c("communis", "socialis", "marxis")

marx <- bigrams |> 
 filter(str_detect(word, paste(free, collapse = "|")))



# enterprise |> 
#   count(word) |> 
#   arrange(desc(n))


marx |> 
  group_by(year) |> 
  count() |> 
ggplot(aes(x= year, y=n, fill=n)) +
  geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1937, 1967, by = 1)) +
  theme(legend.position="none",
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_text(aes(label=n), vjust = -.5, size=3) +
  labs(title = "Marxism in Raymond Moley Newspaper Articles, 1937-1967",
       subtitle = "Analysis of 2,501 Newspaper columns",
       x = "Year",
       y = "Frequency",
       caption = "Marxism, communism, socialism. Source: Newspaper. Graphic by Rob Wells, 6-19-2025")

# ggsave("output/marxism_Newspaper_6-19_2025.png", device = "png", width = 9, height = 6, dpi = 800)

```

#### Bureaucracy
```{r}
free <- c("bureaucra", "socialis", "marxis")

bureaucrat <- bigrams |> 
 filter(str_detect(word, "bureaucr"))



bureaucrat |>
  count(word) |>
  arrange(desc(n))

bureaucrat |> 
  group_by(year) |> 
  count() |> 
ggplot(aes(x= year, y=n, fill=n)) +
  geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1937, 1967, by = 1)) +
  theme(legend.position="none",
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_text(aes(label=n), vjust = -.5, size=3) +
  labs(title = "Bureaucracy in Raymond Moley Newspaper Articles, 1937-1967",
       subtitle = "Analysis of 2,501 Newspaper columns",
       x = "Year",
       y = "Frequency",
       caption = "Source: Newspaper. Graphic by Rob Wells, 6-19-2025")

# ggsave("output/bureaucracy_Newspaper_6-19_2025.png", device = "png", width = 9, height = 6, dpi = 800)

```

#### Spending

expenditures

```{r}
free <- c("expenditures", "spending p", "appropriations")

spend <- bigrams |> 
 filter(str_detect(word, paste(free, collapse = "|")))



spend |>
  count(word) |>
  arrange(desc(n))

spend |> 
  group_by(year) |> 
  count() |> 
ggplot(aes(x= year, y=n, fill=n)) +
  geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1937, 1967, by = 1)) +
  theme(legend.position="none",
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_text(aes(label=n), vjust = -.5, size=3) +
  labs(title = "Government Spending Topics in Raymond Moley Newspaper Articles, 1937-1967",
       subtitle = "Analysis of 2,501 Newspaper columns",
       x = "Year",
       y = "Frequency",
       caption = "Source: Newspaper. Graphic by Rob Wells, 6-19-2025")

# ggsave("output/spending_Newspaper_6-19_2025.png", device = "png", width = 9, height = 6, dpi = 800)

```


#Quanteda search
### Build corpus with unique field id
```{r}

lat_corpus <- articles_text %>%
  mutate(unique_file_id = paste0(new_filename, "_", row_number()))

# Create a corpus using the 'sentence' column as the text field
my_corpus <- corpus(lat_corpus, text_field = "sentence",  docid_field = "unique_file_id") 

# Tokenize the corpus
my_tokens <- tokens(my_corpus)


```

## kwic on politics

```{r}

# Perform KWIC (Key Word in Context) search on the tokens
# quanteda_test <- kwic(my_tokens, pattern = "politics", valuetype = "regex") %>% 
#   as.data.frame()

lat_politics <- kwic(my_tokens, phrase(c("politics", "election", "voter", "precinct")), window = 50, valuetype = "regex") %>% as.data.frame() 

#write.csv(quanteda_test, "quanteda_test.csv")

```

### Extract date and filename
```{r}
lat_politics <- lat_politics |> 
  mutate(date = str_sub(docname, 1, 10)) |> 
  mutate(file_id = str_sub(docname, 12, 22)) |> 
  mutate(date = lubridate::ymd(date)) |> 
  mutate(year = year(date))

lat_politics_unique <- lat_politics |> 
  group_by(date) |> 
  count() |> 
  arrange(desc(n))

```

### Chart newspaper political coverage trends

```{r}

lat_politics |> 
  group_by(year) |> 
  count() |> 
  arrange(desc(n)) |> 
ggplot(aes(x= year, y=n, fill=n)) +
  geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1942, 1969, by = 1)) +
  theme(legend.position="none",
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_text(aes(label=n), vjust = -.5, size=3) +
  labs(title = "Politics Mentioned in Raymond Moley Newspaper Articles, 1937-1967",
       subtitle = "Analysis of 2,501 Newspaper columns",
       x = "Year",
       y = "Frequency",
       caption = "Source: LAT newspaper coverage. Graphic by Rob Wells, 7-24-2025")

# ggsave("output/political_coverage_trends_Newspaper_7-24_2025.png", device = "png", width = 9, height = 6, dpi = 800)

```

# Complacency





```{r}
lat_complacent <- kwic(my_tokens, phrase(c("complacency", "apathy", "self-delusion", "fantastic idea", "blinded them", "lack of active support", "smugness", "overconfidence", "self-satisfaction", "contentment", "inertia", "lethargy", "nonchalance", "indifference", "carelessness", "unconcern", "inattentiveness", "obliviousness", "passivity", "stagnation", "sloth", "negligence", "disregard", "heedlessness", "rashness", "shortsightedness", "overoptimism", "hubris", "presumption", "false sense of security", "lack of urgency", "laissez-faire attitude", "blasé outlook", "unresponsiveness", "torpor", "dormancy")), window = 50, valuetype = "regex") %>% as.data.frame() 

#write.csv(quanteda_test, "quanteda_test.csv")

```

### Extract date and filename
```{r}
lat_complacent <- lat_complacent |> 
  mutate(date = str_sub(docname, 1, 10)) |> 
  mutate(file_id = str_sub(docname, 12, 22)) |> 
  mutate(date = lubridate::ymd(date)) |> 
  mutate(year = year(date))

lat_complacent_unique <- lat_complacent|> 
  group_by(date) |> 
  count() |> 
  arrange(desc(n))

```

### Chart newspaper political coverage trends

```{r}

lat_complacent |> 
  group_by(year) |> 
  count() |> 
  arrange(desc(n)) |> 
ggplot(aes(x= year, y=n, fill=n)) +
  geom_bar(stat="identity", position="dodge") +
scale_x_continuous(breaks = seq(1942, 1969, by = 1)) +
  theme(legend.position="none",
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_text(aes(label=n), vjust = -.5, size=3) +
  labs(title = "Complacency Mentioned in Raymond Moley Newspaper Articles, 1937-1967",
       subtitle = "Analysis of 2,501 Newspaper columns",
       x = "Year",
       y = "Frequency",
       caption = "Source: LAT newspaper coverage. Graphic by Rob Wells, 7-24-2025")

# ggsave("output/complacency_newspaper_7-24_2025.png", device = "png", width = 9, height = 6, dpi = 800)

```


# Link the results with the metadata
```{r}
#Strips out unique file name from article index 
kwic_results <- kwic_results |>  
    mutate(matchrow = str_extract(docname, "^[^_]+_[^_]+"))

metadata <- extracted_articles_index_oct_16_2024

# Join KWIC results with metadata 
kwic_with_metadata <- kwic_results %>%
  inner_join(metadata, by = c("matchrow"="file_id")) |> 
  distinct(docname, .keep_all= TRUE) |> 
  select(matchrow, date, from, to, pre, keyword, post, pattern, newspaper_name, newspaper_city, newspaper_state,black_press,url, docname)
```


# Housecleaning
```{r}
#cut useless returns
mobjunk <- c("mobile",  "automobile",  "automobiles", "mobilize", "mobley", "mobilizing", "democratic party of", "mobe", "moberly",  "mobil", "mobiles", "mobilized", "mobold")
kwic_with_metadata <- kwic_with_metadata %>%
  filter(!keyword %in% mobjunk)


#Eliminate duplication
kwic_with_metadata  <- kwic_with_metadata  %>% 
  distinct(docname, pre, keyword, post, newspaper_name, date, url) %>% 
  rename('Beginning of Passage' = pre, 'End of Passage' = post, Newspaper = newspaper_name, Date = date) 

kwic_with_metadata_csv <- kwic_with_metadata  %>%
  add_column(Code = NA) %>% 
  add_column(Comments = NA) %>% 
  select(docname, Newspaper, Date, 'Beginning of Passage', keyword, 'End of Passage', Code, Comments)

#write_csv(kwic_with_metadata_csv, "../exercises/assets/data/kwic_with_metadata.csv")

```






# Bigrams
```{r}
bigrams <- articles_text |> mutate(sentence= str_squish(sentence)) |> 
  mutate(text = tolower(sentence)) |>  
  mutate(text = gsub("\\d+", "", text)) |>
  mutate(text = str_replace_all(text, "raymond", "")) |>
  mutate(text = str_replace_all(text, "newsweek", "")) |>
  mutate(text = str_replace_all(text, "image", "")) |>
  mutate(text = str_replace_all(text, "perspective", "")) |>
  mutate(text = str_replace_all(text, "registered u.s. patent office", "")) |>
  mutate(text = str_replace_all(text, "reproduced with permission of the copyright owner", "")) |>
  mutate(text = str_replace_all(text, "further reproduction prohibited without permission", "")) |>
  mutate(text = str_replace_all(text, "copyright", "")) |>
  mutate(text = str_replace_all(text, "new york city", "")) |>
  mutate(text = str_replace_all(text, "- ", "")) |>
  mutate(text = str_replace_all(text, " -", "")) |>
  mutate(text = str_replace_all(text, " - ", "")) |>
  unnest_tokens(word, text, token="ngrams", n=2 ) |>
  filter(!word %in% stop_words$word) |>
  filter(!word == "minor inaccuracies") |>
  filter(!word == "text extraction") |>
  filter(!word == "text version") |>
  filter(!word == "copyright owner") |>
  filter(!word == "reproduction prohibited") |>
  filter(!is.na(word))

bigrams <- bigrams |>
  select(word, date, year, filename)

```

## Datatable with bigrams
```{r}
bigrams_separated <- bigrams |>
  separate(word, c("word1", "word2"), sep = " ")

#bigrams with stop words filtered

bigrams_filtered <- 
  bigrams_separated |>
  filter(!word1 %in% stop_words$word) |>
  filter(!word2 %in% stop_words$word)

bigram_counts <- bigrams_filtered |>
  count(word1, word2, sort = TRUE) |> 
  filter(!is.na(word1))

datatable(bigram_counts,
          caption = "Top Bigrams",
          options = list(pageLength = 20))

```



There are 288 word pairs containing "Nixon."
There are 256 word pairs containing "Dewey."
There are 96 word pairs containing "Goldwater."
There are 269 word pairs containing "Eisenhower."
There are 425 word pairs containing "Roosevelt."
There are 382 word pairs containing "Truman."
There are 271 word pairs containing "Kennedy."

```{r}
  
top_20_bigrams <- bigram_counts |> 
   top_n(20) |> 
  mutate(bigram = paste(word1, " ", word2)) |> 
  select(bigram, n)

ggplot(top_20_bigrams, aes(n, reorder(bigram, n), fill=n)) +
  geom_bar(stat="identity", position="dodge") +
  theme(legend.position="none") +
  geom_text(aes(label=n), hjust=-0.2, size=3) +
  labs(title = "Raymond Moley Newspaper Column Phrases, 1942-1969",
       subtitle = "Analysis of 2,501 newspaper columns",
       x = "Count",
       y = "Bigrams",
       caption = "Source: Newsweek. Graphic by Rob Wells, 6-21-2025")
```


Counting Word instances
```{r}


articles_text |>
  # First ensure sentence is character and lowercase
  mutate(sentence = as.character(sentence),
         sentence = tolower(sentence)) |>
  # Group by filename to avoid double-counting articles
  group_by(filename) |>
  summarise(
    nixon = sum(str_count(sentence, "nixon"), na.rm = TRUE),
    goldwater = sum(str_count(sentence, "goldwater"), na.rm = TRUE),
    dewey = sum(str_count(sentence, "dewey"), na.rm = TRUE),
    eisenhower = sum(str_count(sentence, "eisenhower"), na.rm = TRUE),
    truman = sum(str_count(sentence, "truman"), na.rm = TRUE),
    kennedy = sum(str_count(sentence, "kennedy"), na.rm = TRUE)
  ) |>
  # Now get totals across all articles
  summarise(
    nixon = sum(nixon),
    goldwater = sum(goldwater),
    dewey = sum(dewey),
    eisenhower = sum(eisenhower),
    truman = sum(truman),
    kennedy = sum(kennedy)
  ) |>
  pivot_longer(
    everything(),
    names_to = "politician",
    values_to = "count"
  ) |>
  mutate(percentage = (count / 2501) * 100) |>
  arrange(desc(count))
```

In Newsweek:

politician
<chr>
count
<int>
percentage
<dbl>
dewey	668	44.92266		
eisenhower	456	30.66577		
nixon	348	23.40282		
goldwater	254	17.08137	



## Presidential Candidate Coverage

###Kennedy
```{r}
kennedy_articles2 <- articles_text |>
  filter(!is.na(sentence)) |>
  group_by(filename, year, date) |>
  summarize(mentions = sum(str_detect(sentence, "Kennedy"), na.rm = TRUE)) |>
  filter(mentions >= 2) |> 
  mutate(politician = "Kennedy")

kennedy_mentions <- articles_text |>
  filter(!is.na(sentence)) |>
  filter(str_detect(sentence, "Kennedy"))

print(paste("Total number of sentences mentioning Kennedy:", nrow(kennedy_mentions)))
```


###Truman
```{r}
truman_articles2 <- articles_text |>
  filter(!is.na(sentence)) |>
  group_by(filename, year, date) |>
  summarize(mentions = sum(str_detect(sentence, "Truman"), na.rm = TRUE)) |>
  filter(mentions >= 2) |> 
  mutate(politician = "Truman")


truman_mentions <- articles_text |>
  filter(!is.na(sentence)) |>
  filter(str_detect(sentence, "Truman"))

print(paste("Total number of sentences mentioning Truman:", nrow(truman_mentions)))
```


###Nixon
```{r}
nixon_articles2 <- articles_text |>
  filter(!is.na(sentence)) |>
  group_by(filename, year, date) |>
  summarize(mentions = sum(str_detect(sentence, "Nixon"), na.rm = TRUE)) |>
  filter(mentions >= 2) |> 
  mutate(politician = "Nixon")


nixon_mentions <- articles_text |>
  filter(!is.na(sentence)) |>
  filter(str_detect(sentence, "Nixon"))

print(paste("Total number of sentences mentioning Nixon:", nrow(nixon_mentions)))
```
###Goldwater
```{r}
goldwater_articles2 <- articles_text |>
  filter(!is.na(sentence)) |>
  group_by(filename, year, date) |>
  summarize(mentions = sum(str_detect(sentence, "Goldwater"), na.rm = TRUE)) |>
  filter(mentions >= 2) |> 
    mutate(politician = "Goldwater")


goldwater_mentions <- articles_text |>
  filter(!is.na(sentence)) |>
  filter(str_detect(sentence, "Goldwater"))

print(paste("Total number of sentences mentioning Goldwater:", nrow(goldwater_mentions)))
```
###Roosevelt
```{r}
roosevelt_articles2 <- articles_text |>
  filter(!is.na(sentence)) |>
  group_by(filename, year, date) |>
  summarize(mentions = sum(str_detect(sentence, "Roosevelt"), na.rm = TRUE)) |>
  filter(mentions >= 2) |> 
    mutate(politician = "Roosevelt")


roosevelt_mentions <- articles_text |>
  filter(!is.na(sentence)) |>
  filter(str_detect(sentence, "Roosevelt"))

print(paste("Total number of sentences mentioning Roosevelt:", nrow(roosevelt_mentions)))
```
###Eisenhower
```{r}
eisenhower_articles2 <- articles_text |>
  filter(!is.na(sentence)) |>
  group_by(filename, year, date) |>
  summarize(mentions = sum(str_detect(sentence, "Eisenhower"), na.rm = TRUE)) |>
  filter(mentions >= 2) |> 
    mutate(politician = "Eisenhower")


eisenhower_mentions <- articles_text |>
  filter(!is.na(sentence)) |>
  filter(str_detect(sentence, "Eisenhower"))

print(paste("Total number of sentences mentioning eisenhower:", nrow(eisenhower_mentions)))
```
###Dewey
```{r}
dewey_articles2 <- articles_text |>
  filter(!is.na(sentence)) |>
   group_by(filename, year, date) |>
  summarize(mentions = sum(str_detect(sentence, "Dewey"), na.rm = TRUE)) |>
  filter(mentions >= 2) |> 
    mutate(politician = "Dewey")


dewey_mentions <- articles_text |>
  filter(!is.na(sentence)) |>
  filter(str_detect(sentence, "Dewey"))

print(paste("Total number of sentences mentioning dewey:", nrow(dewey_mentions)))
```

```{r}
politicians <- rbind(nixon_articles2, goldwater_articles2, roosevelt_articles2, dewey_articles2, eisenhower_articles2, truman_articles2, kennedy_articles2)

#write.csv(politicians, "politicians_mentions_feb21.csv")
```
###Candidates visualized
```{r}
politician_colors <- c(
  "Truman" = "#1f77b4",     # Blue
  "Eisenhower" = "#ff7f0e", # Orange
  "Dewey" = "#2ca02c",      # Green
  "Nixon" = "#d62728",      # Red
  "Goldwater" = "#9467bd",  # Purple
  "Kennedy" = "black",    # black
  "Roosevelt" = "#e377c2"   # Pink
)

politicians |> 
  group_by(year, politician) |> 
  summarize(total = sum(mentions)) |> 
ggplot(aes(y=total, x= year, fill=politician)) +
  geom_bar(stat="identity", position="dodge") +
  scale_fill_manual(values = politician_colors) +  
  scale_x_continuous(breaks = seq(1942, 1969, by = 2))+
  labs(title = "Moley's Coverage of Major Candidates",
       subtitle = "Two or more mentions of politician in Moley's newspaper column",
        y = "Count of Politician Mentions", 
        x = "",
        caption = "n=2,501 newspaper articles, Graphic by Rob Wells") +
  theme(axis.text.x = element_text(angle = 45, vjust=0.5))


```




```{r echo = F}
nixon_articles <- articles_text |>
  filter(str_detect(sentence, "Nixon")) |>
  select(filename, year) |>
  distinct(filename, year)


goldwater_articles <- articles_text |>
  filter(str_detect(sentence, "Goldwater")) |>
  select(filename, year) |>
  distinct(filename, year)

roosevelt_articles <- articles_text |>
  filter(str_detect(sentence, "Roosevelt")) |>
  select(filename, year) |>
  distinct(filename, year)

dewey_articles <- articles_text |>
  filter(str_detect(sentence, "Dewey")) |>
  select(filename, year) |>
  distinct(filename, year)

truman_articles <- articles_text |>
  filter(str_detect(sentence, "Truman")) |>
  select(filename, year) |>
  distinct(filename, year)

kennedy_articles <- articles_text |>
  filter(str_detect(sentence, "Kennedy")) |>
  select(filename, year) |>
  distinct(filename, year)


nrc_sentiments <- get_sentiments("nrc")
afinn_sentiments <- get_sentiments("afinn")

```

### Dewey

```{r echo = F, results = 'hide', error=F, warning=F, message=F}

dewey_text <- articles_text |>
  select(filename, year, sentence) |>
  filter(filename %in% dewey_articles$filename)


dewey_text_tokenized <- dewey_text |> 
  select(sentence) |> 
  mutate(sentence = str_replace_all(sentence, "- ", "")) |> 
  unnest_tokens(word, sentence) |> 
  filter(!word %in% stop_words$word) |> 
  filter(!grepl('[0-9]', word))

dewey_sentiments_all <- dewey_text_tokenized |>
  inner_join(nrc_sentiments, relationship = "many-to-many") |>
  count(sentiment, sort = TRUE) |> 
  mutate(pct_total = round(n/sum(n), digits=4)) |>
  mutate(president = "Dewey") |>
  # Reorder sentiment based on pct_total
  mutate(sentiment = reorder(sentiment, -pct_total))

ggplot(dewey_sentiments_all, aes(sentiment, pct_total, fill=pct_total)) +
  geom_bar(stat="identity", position="dodge") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 0.01)) +  # Format y-axis as percentages
  labs(title = "Sentiment of Thomas Dewey Articles",
        x = "Sentiment",
        y = "Percentage of Total Text", 
        caption = "Newsweek articles, Graphic by Rob Wells and Bridget Lang") +
  theme(axis.text.x = element_text(angle = 45, vjust=0.5),legend.position = "none") 
```

### Nixon

```{r}

nixon_text <- articles_text |>
  select(filename, year, sentence) |>
  filter(filename %in% nixon_articles$filename)


nixon_text_tokenized <- nixon_text |> 
  select(sentence) |> 
  mutate(sentence = str_replace_all(sentence, "- ", "")) |> 
  unnest_tokens(word, sentence) |> 
  filter(!word %in% stop_words$word) |> 
  filter(!grepl('[0-9]', word))

nixon_sentiments_all <- nixon_text_tokenized |>
  inner_join(nrc_sentiments, relationship = "many-to-many") |>
  count(sentiment, sort = TRUE) |> 
  mutate(pct_total = round(n/sum(n), digits=4)) |>
  mutate(president = "Nixon") |>
  # Reorder sentiment based on pct_total
  mutate(sentiment = reorder(sentiment, -pct_total))

ggplot(nixon_sentiments_all, aes(sentiment, pct_total, fill=pct_total)) +
  geom_bar(stat="identity", position="dodge") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 0.01)) +  # Format y-axis as percentages
  labs(title = "Sentiment of Nixon Articles",
        x = "Sentiment",
        y = "Percentage of Total Text", 
        caption = "Newsweek articles, Graphic by Rob Wells and Bridget Lang") +
  theme(axis.text.x = element_text(angle = 45, vjust=0.5),legend.position = "none") 
```

### Nixon v Dewey Sentiment

```{r}

nixon_dewey_sentiments <- dewey_sentiments_all |>
  bind_rows(nixon_sentiments_all)


ggplot(nixon_dewey_sentiments, aes(sentiment, pct_total, fill=president)) +
  geom_bar(stat="identity", position="dodge") +
  scale_y_continuous(labels = scales::percent, limits=c(0, .30)) +
  geom_text(aes(label=scales::percent(pct_total, accuracy=0.01), group=president), 
            position = position_dodge(width=0.9),  # Match the dodge width of bars
            angle = 90,                            # Rotate text 90 degrees
            hjust = -0.2,                         # Adjust horizontal position
            size=3) +
  labs(title = "Sentiment Nixon vs. Dewey in Moley Newspaper Columns",
       x = "Sentiment",
       y = "Percentage of Total Text",
       caption = "Graphic by Rob Wells and Bridget Lang, 6/22/2025") + 
  theme(axis.text.x = element_text(angle = 45, vjust=0.5)) + 
  scale_fill_manual(values = c("forestgreen", "purple"))


```


# Kennedy sentiment
```{r echo = F, results = 'hide', error=F, warning=F, message=F}

kennedy_text <- articles_text |>
  select(filename, year, sentence) |>
  filter(filename %in% kennedy_articles$filename)


kennedy_text_tokenized <- kennedy_text |> 
  select(sentence) |> 
  mutate(sentence = str_replace_all(sentence, "- ", "")) |> 
  unnest_tokens(word, sentence) |> 
  filter(!word %in% stop_words$word) |> 
  filter(!grepl('[0-9]', word))

kennedy_sentiments_all <- kennedy_text_tokenized |>
  inner_join(nrc_sentiments, relationship = "many-to-many") |>
  count(sentiment, sort = TRUE) |> 
  mutate(pct_total = round(n/sum(n), digits=4)) |>
  mutate(president = "Kennedy") |>
  # Reorder sentiment based on pct_total
  mutate(sentiment = reorder(sentiment, -pct_total))

ggplot(kennedy_sentiments_all, aes(sentiment, pct_total, fill=pct_total)) +
  geom_bar(stat="identity", position="dodge") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 0.01)) +  # Format y-axis as percentages
  labs(title = "Sentiment of Kennedy Articles",
        x = "Sentiment",
        y = "Percentage of Total Text", 
        caption = "Newspaper articles, Graphic by Rob Wells and Bridget Lang") +
  theme(axis.text.x = element_text(angle = 45, vjust=0.5),legend.position = "none") 
```

# Kennedy v Nixon sentiment
```{r}

nixon_kennedy_sentiments <- kennedy_sentiments_all |>
  bind_rows(nixon_sentiments_all)


ggplot(nixon_kennedy_sentiments, aes(sentiment, pct_total, fill=president)) +
  geom_bar(stat="identity", position="dodge") +
  scale_y_continuous(labels = scales::percent, limits=c(0, .30)) +
  geom_text(aes(label=scales::percent(pct_total, accuracy=0.01), group=president), 
            position = position_dodge(width=0.9),  # Match the dodge width of bars
            angle = 90,                            # Rotate text 90 degrees
            hjust = -0.2,                         # Adjust horizontal position
            size=3) +
  labs(title = "Sentiment Nixon vs. kennedy in Moley Newspaper Columns",
       x = "Sentiment",
       y = "Percentage of Total Text",
       caption = "Graphic by Rob Wells and Bridget Lang, 6/22/2025") + 
  theme(axis.text.x = element_text(angle = 45, vjust=0.5)) + 
  scale_fill_manual(values = c("forestgreen", "purple"))


```




# Words in headlines
Count the words in the Perspective column headlines
```{r}

headlines_tokens <- article_index |> 
  mutate(text= str_squish(title), 
      text = tolower(text),
      text = str_remove_all(text, "[[:punct:]]")) |> 
  unnest_tokens(word, text, token="ngrams", n=1 ) |>
  filter(!word %in% stop_words$word) |>
  filter(!is.na(word)) |> 
  filter(!word == "perspective") |>
  select(word, date, year, index)


headline_counts <- headlines_tokens |>
  count(word, sort = TRUE) |> 
  filter(!is.na(word))

datatable(headline_counts,
          caption = "Top Words in Moley Newspaper Headlines",
          options = list(pageLength = 15))


```

Dewey and its variants appeared in headlines 29 times, which would have made it a top xx term.

Nixon and its variants appeared 46 times in headlines, which would have made it a top 4 term.

Goldwater appeared 8 times. Eisenhower, 30; Wilkie, 0; Roosevelt, 13; Kennedy, 40; Truman, 49
Republican was the with 30 mentions; Democrats, 19

