---
title: "Content Analysis of Raymond Moleyâ€™s Reporting from 1937 - 1968"
author: "Rob Wells and Bridget Lang"
date: '2025-2-14'
output: html_document
---

This project aims to perform a basic narrative and topic analysis of the journalism of **Raymond Moley**, a prominent columnist who advocated a centrist conservative political vision from 1937 through 1967 in his books, weekly Newsweek column and syndicated newspaper column. 

The goal of this project is to **measure patterns in wording, verbiage, themes, and sentiment** of Raymond Moley's poltitical reporting over time. This research will support a larger effort in analyzing the **influence of journalism and polticial activism on American elections, voting, and democracy at large**. 

I am focusing on the time period of Moley's work from **1937-1968**, with **1400 articles**  analyzed. 

The index has 1562 articles
The earliest year of publication is 1937, and the latest is 1967.
The average year of publication is 1952, with the majority of articles written in 1938.
The article text has 1487 articles. That's less than the 1562 entries in the article index. The difference was due to about 75 failed AI scans.

# Load Libraries
```{r message=FALSE, warning=FALSE, include=FALSE}


library(textdata)
library(tidyverse)
library(pdftools)
library(dplyr)
library(rio)
library(tidytext)
library(quanteda)
library(knitr)
library(formattable)
library(forcats)
library(readtext)
#topic modeling
library(tm)
library(topicmodels)
library(lda)
library(ldatuning)
# from tutorial packages
library(DT)
library(knitr) 
library(kableExtra) 
library(reshape2)
library(ggplot2)
library(wordcloud)
library(pals)
library(SnowballC)
library(flextable)
library(janitor)
```

## Load Data
```{r echo = F}
#1562 articles in index
article_index <-  rio::import("matching with extract-Perspective_full_index_1967_1937.xls") |> 
  clean_names() |> 
  mutate(year = as.numeric(year),
         date = as.Date(pubdate, format="%b %d, %Y"))

#136596 rows of text
articles_text <-  read_csv("/Users/gizmofo/Library/CloudStorage/Dropbox/Current_Projects/Moley project 2024/moley_cleaned_perspective_text.csv") |> 
    mutate(year = as.numeric(year),
         date = as.Date(pubdate, format="%b %d, %Y"))
```
## Statistics about the index 
```{r}

nrows <- nrow(article_index)
ncols <- ncol(article_index)

mean_year <- round(mean(article_index$year, na.rm = TRUE),0)

min_year <- min(article_index$year)

max_year <- max(article_index$year)


year_counts <- 
  article_index %>%
  count(year)

max_count <- max(year_counts$n)
max_years <- year_counts %>%
  select(year) %>%
  filter(year_counts$n == max_count)
                  

glue::glue("There are {nrows} articles in the index of Moley Newsweek columns.");

glue::glue("The earliest year of publication is {as.integer(min_year)}, and the latest is {max_year}.")

glue::glue("The average year of publication is {as.integer(mean_year)}, with the majority of articles written in {max_years$year}.")




```

## Statistics about the extracted text
```{r echo = F}
nrows1 <- nrow(articles_text)
ncols1 <- ncol(articles_text)

articles <- articles_text |> 
  distinct(filename) |> 
  count()


glue::glue("The article text has {articles} articles. That's less than the {nrows} entries in the article index. The difference was due to about {nrows-articles} failed AI scans.")
glue::glue("The article text dataframe is huge, with {nrows1} rows and {ncols1} columns.")

```


# Figure x: Articles over time

```{r}

#Here is a chart, Figure x, that counts columns by year
count_year <- articles_text %>% 
  distinct(filename, .keep_all = TRUE) |> 
count(year) %>% 
#Sandwich it onto a simple ggplot
  ggplot(aes(x = year, y = n, fill = n)) +
  geom_col(position = "dodge") + 
  theme(legend.position = "none") +
  scale_x_continuous(breaks = seq(1935, 1970, by = 5))+
  labs(title = "Moley Newsweek Columns By Year, 1937-1967", 
       subtitle = "Extracted Text Only",
       caption = "n=1,487  articles. Graphic by Rob Wells, 2/14/2025",
       y="Count of Pages",
       x="Year")

count_year

#ggsave(here::here("Figure_X_ columns_by_year_2_14_2025.png"),device = "png",width=9,height=6, dpi=800)

```


# Bigrams
```{r}
bigrams <- articles_text %>% mutate(sentence= str_squish(sentence)) |> 
  mutate(text = tolower(sentence)) |>  
  mutate(text = gsub("\\d+", "", text)) |>
  mutate(text = str_replace_all(text, "raymond", "")) %>% 
  mutate(text = str_replace_all(text, "newsweek", "")) %>% 
  mutate(text = str_replace_all(text, "image", "")) %>%
  mutate(text = str_replace_all(text, "perspective", "")) %>%
  mutate(text = str_replace_all(text, "registered u.s. patent office", "")) %>%
  mutate(text = str_replace_all(text, "- ", "")) %>%
  mutate(text = str_replace_all(text, " -", "")) %>%
  mutate(text = str_replace_all(text, " - ", "")) %>%
  unnest_tokens(word, text, token="ngrams", n=2 ) %>%
  filter(!word %in% stop_words$word) %>%
  filter(!word == "minor inaccuracies") %>%
  filter(!word == "text extraction") %>%
  filter(!word == "text version") %>%
    filter(!is.na(word))

bigrams <- bigrams %>%
  select(word, date, year, filename)

```

## Datatable with bigrams
```{r}
bigrams_separated <- bigrams %>%
  separate(word, c("word1", "word2"), sep = " ")

#bigrams with stop words filtered

bigrams_filtered <- 
  bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

bigram_counts <- bigrams_filtered %>%
  count(word1, word2, sort = TRUE) %>% 
  filter(!is.na(word1))

datatable(bigram_counts,
          caption = "Top Bigrams",
          options = list(pageLength = 20))

```



There are 192 word pairs containing "Nixon."
There are 300 word pairs containing "Dewey."
There are 139 word pairs containing "Goldwater."


```{r}
  
top_20_bigrams <- bigram_counts |> 
   top_n(20) |> 
  mutate(bigram = paste(word1, " ", word2)) |> 
  select(bigram, n)

ggplot(top_20_bigrams, aes(n, reorder(bigram, n), fill=n)) +
  geom_bar(stat="identity", position="dodge") +
  theme(legend.position="none") +
  geom_text(aes(label=n), hjust=-0.2, size=3) +
  labs(title = "Raymond Moley Common Phrases, 1937-1967",
       subtitle = "Analysis of 1,487 Newsweek columns",
       x = "Count",
       y = "Bigrams",
       caption = "Source: Newsweek. Graphic by Rob Wells and Bridget Lang, 2-14-2024")
```


Counting Word instances
```{r}


articles_text %>%
  # First ensure sentence is character and lowercase
  mutate(sentence = as.character(sentence),
         sentence = tolower(sentence)) %>%
  # Group by filename to avoid double-counting articles
  group_by(filename) %>%
  summarise(
    nixon = sum(str_count(sentence, "nixon"), na.rm = TRUE),
    goldwater = sum(str_count(sentence, "goldwater"), na.rm = TRUE),
    dewey = sum(str_count(sentence, "dewey"), na.rm = TRUE),
    eisenhower = sum(str_count(sentence, "eisenhower"), na.rm = TRUE)
  ) %>%
  # Now get totals across all articles
  summarise(
    nixon = sum(nixon),
    goldwater = sum(goldwater),
    dewey = sum(dewey),
    eisenhower = sum(eisenhower)
  ) %>%
  pivot_longer(
    everything(),
    names_to = "politician",
    values_to = "count"
  ) %>%
  mutate(
    percentage = count / 1487) * 100  # Using actual number of articles
  ) %>%
  arrange(desc(count))
```




## Presidential Candidate Coverage
###Nixon
```{r}
nixon_articles2 <- articles_text %>%
  filter(!is.na(sentence)) %>%
  group_by(filename, year, date) %>%
  summarize(mentions = sum(str_detect(sentence, "Nixon"), na.rm = TRUE)) %>%
  filter(mentions >= 2) |> 
  mutate(politician = "Nixon")

# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
nixon_mentions <- articles_text %>%
  filter(!is.na(sentence)) %>%
  filter(str_detect(sentence, "Nixon"))

print(paste("Total number of sentences mentioning Nixon:", nrow(nixon_mentions)))
```
###Goldwater
```{r}
goldwater_articles2 <- articles_text %>%
  filter(!is.na(sentence)) %>%
  group_by(filename, year, date) %>%
  summarize(mentions = sum(str_detect(sentence, "Goldwater"), na.rm = TRUE)) %>%
  filter(mentions >= 2) |> 
    mutate(politician = "Goldwater")

# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
goldwater_mentions <- articles_text %>%
  filter(!is.na(sentence)) %>%
  filter(str_detect(sentence, "Goldwater"))

print(paste("Total number of sentences mentioning Goldwater:", nrow(goldwater_mentions)))
```
###Roosevelt
```{r}
roosevelt_articles2 <- articles_text %>%
  filter(!is.na(sentence)) %>%
  group_by(filename, year, date) %>%
  summarize(mentions = sum(str_detect(sentence, "Roosevelt"), na.rm = TRUE)) %>%
  filter(mentions >= 2) |> 
    mutate(politician = "Roosevelt")

# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
roosevelt_mentions <- articles_text %>%
  filter(!is.na(sentence)) %>%
  filter(str_detect(sentence, "Roosevelt"))

print(paste("Total number of sentences mentioning Roosevelt:", nrow(roosevelt_mentions)))
```
###Eisenhower
```{r}
eisenhower_articles2 <- articles_text %>%
  filter(!is.na(sentence)) %>%
  group_by(filename, year, date) %>%
  summarize(mentions = sum(str_detect(sentence, "Eisenhower"), na.rm = TRUE)) %>%
  filter(mentions >= 2) |> 
    mutate(politician = "Eisenhower")

# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
eisenhower_mentions <- articles_text %>%
  filter(!is.na(sentence)) %>%
  filter(str_detect(sentence, "Eisenhower"))

print(paste("Total number of sentences mentioning eisenhower:", nrow(eisenhower_mentions)))
```
###Dewey
```{r}
dewey_articles2 <- articles_text %>%
  filter(!is.na(sentence)) %>%
   group_by(filename, year, date) %>%
  summarize(mentions = sum(str_detect(sentence, "Dewey"), na.rm = TRUE)) %>%
  filter(mentions >= 2) |> 
    mutate(politician = "Dewey")

# Let's also check the intermediate steps to debug:
# First check if we're finding any Nixon mentions at all
dewey_mentions <- articles_text %>%
  filter(!is.na(sentence)) %>%
  filter(str_detect(sentence, "Dewey"))

print(paste("Total number of sentences mentioning dewey:", nrow(dewey_mentions)))
```

```{r}
politicians <- rbind(nixon_articles2, goldwater_articles2, roosevelt_articles2, dewey_articles2, eisenhower_articles2)

#write.csv(politicians, "politicians_mentions_feb21.csv")
```
###Candidates visualized
```{r}
politicians |> 
  group_by(year, politician) |> 
  summarize(total = sum(mentions)) |> 
ggplot(aes(y=total, x= year, fill=politician)) +
  geom_bar(stat="identity", position="dodge") +
  scale_x_continuous(breaks = seq(1936, 1968, by = 2))+
  labs(title = "Moley's Coverage of Major Candidates",
       subtitle = "Two or more mentions of politician in Newsweek",
        y = "Count of Politician Mentions", 
        x = "",
        caption = "n=1,487 Newsweek articles, Graphic by Rob Wells") +
  theme(axis.text.x = element_text(angle = 45, vjust=0.5)) 


```




```{r echo = F}
nixon_articles <- articles_text %>%
  filter(str_detect(sentence, "Nixon")) %>%
  select(filename, year) %>%
  distinct(filename, year)


goldwater_articles <- articles_text %>%
  filter(str_detect(sentence, "Goldwater")) %>%
  select(filename, year) %>%
  distinct(filename, year)

roosevelt_articles <- articles_text %>%
  filter(str_detect(sentence, "Roosevelt")) %>%
  select(filename, year) %>%
  distinct(filename, year)

dewey_articles <- articles_text %>%
  filter(str_detect(sentence, "Dewey")) %>%
  select(filename, year) %>%
  distinct(filename, year)


nrc_sentiments <- get_sentiments("nrc")
afinn_sentiments <- get_sentiments("afinn")

```

### Dewey

```{r echo = F, results = 'hide', error=F, warning=F, message=F}

dewey_text <- articles_text %>%
  select(filename, year, sentence) %>%
  filter(filename %in% dewey_articles$filename)


dewey_text_tokenized <- dewey_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

dewey_sentiments_all <- dewey_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total = round(n/sum(n), digits=4)) %>%
  mutate(president = "Dewey") %>%
  # Reorder sentiment based on pct_total
  mutate(sentiment = reorder(sentiment, -pct_total))

ggplot(dewey_sentiments_all, aes(sentiment, pct_total, fill=pct_total)) +
  geom_bar(stat="identity", position="dodge") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 0.01)) +  # Format y-axis as percentages
  labs(title = "Sentiment of Thomas Dewey Articles",
        x = "Sentiment",
        y = "Percentage of Total Text", 
        caption = "Newsweek articles, Graphic by Rob Wells and Bridget Lang") +
  theme(axis.text.x = element_text(angle = 45, vjust=0.5),legend.position = "none") 
```

### Nixon

```{r}

nixon_text <- articles_text %>%
  select(filename, year, sentence) %>%
  filter(filename %in% nixon_articles$filename)


nixon_text_tokenized <- nixon_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

nixon_sentiments_all <- nixon_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total = round(n/sum(n), digits=4)) %>%
  mutate(president = "Nixon") %>%
  # Reorder sentiment based on pct_total
  mutate(sentiment = reorder(sentiment, -pct_total))

ggplot(nixon_sentiments_all, aes(sentiment, pct_total, fill=pct_total)) +
  geom_bar(stat="identity", position="dodge") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 0.01)) +  # Format y-axis as percentages
  labs(title = "Sentiment of Nixon Articles",
        x = "Sentiment",
        y = "Percentage of Total Text", 
        caption = "Newsweek articles, Graphic by Rob Wells and Bridget Lang") +
  theme(axis.text.x = element_text(angle = 45, vjust=0.5),legend.position = "none") 
```

# Nixon v Dewey Sentiment

```{r}

nixon_dewey_sentiments <- dewey_sentiments_all %>%
  bind_rows(nixon_sentiments_all)


ggplot(nixon_dewey_sentiments, aes(sentiment, pct_total, fill=president)) +
  geom_bar(stat="identity", position="dodge") +
  scale_y_continuous(labels = scales::percent, limits=c(0, .30)) +
  geom_text(aes(label=scales::percent(pct_total, accuracy=0.01), group=president), 
            position = position_dodge(width=0.9),  # Match the dodge width of bars
            angle = 90,                            # Rotate text 90 degrees
            hjust = -0.2,                         # Adjust horizontal position
            size=3) +
  labs(title = "Sentiment Nixon vs. Dewey in Moley Columns",
       x = "Sentiment",
       y = "Percentage of Total Text",
       caption = "Graphic by Bridget Lang and Rob Wells, 2/16/2025") + 
  theme(axis.text.x = element_text(angle = 45, vjust=0.5)) + 
  scale_fill_manual(values = c("forestgreen", "purple"))


```

# Words in headlines
Count the words in the Perspective column headlines
```{r}

headlines_tokens <- article_index |> 
  mutate(text= str_squish(title), 
      text = tolower(text),
      text = str_remove_all(text, "[[:punct:]]")) |> 
  unnest_tokens(word, text, token="ngrams", n=1 ) %>%
  filter(!word %in% stop_words$word) %>%
  filter(!is.na(word)) |> 
  filter(!word == "perspective") %>%
  select(word, date, year, index)


headline_counts <- headlines_tokens %>%
  count(word, sort = TRUE) %>% 
  filter(!is.na(word))

datatable(headline_counts,
          caption = "Top Words in Moley Headlines",
          options = list(pageLength = 15))


```

Dewey and its variants appeared in headlines 18 times, which would have made it a top 10 term.

Nixon and its variants appeared 16 times in headlines, which would have made it a top 15 term.

Goldwater appeared 7 times. Eisenhower, 3; Wilkie, 0; Roosevelt, 9; Kennedy, 6; Truman, 7
Republican was the 8th most frequent term with 18 mentions; Democrats, 5, around 80th place.


# Articles - Politicians

```{r}




```



#----------------------------------------
# Notes Below
#----------------------------------------

## Overall Sentiment Analysis 

### All Articles
#rsw comment - again, fix the y axis to scale as percentages. 
```{r echo = F, results = 'hide', error=F, warning=F, message=F}

all_text_tokenized <- articles_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

sentiments_all <- all_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total =round(n/sum(n), digits=2))

sentiments_all <- sentiments_all %>%
  mutate(percent = percent(pct_total)) %>%
  mutate(sentiment = fct_reorder(sentiment, desc(percent)))

ggplot(sentiments_all, aes(sentiment, percent, fill=percent)) +
  geom_bar(stat="identity", position="dodge") +
  labs(title = "Presence of Sentiment in Articles by Raymond Moley, 1942-1964",
        x = "Sentiment",
        y = "Percentage of Total Text")

```

### By Decade

#rsw comment; great idea. the bars need to be in chronological sequence, though. An easier way would be to mutate a new decade variable and visualize that instead.
```{r echo = F, results = 'hide', error=F, warning=F, message=F}
#fourties
fourties_text <- articles_text %>% 
  filter((round(year / 10) * 10) == 1940)

fourties_text_tokenized <- fourties_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

fourties_sentiments <- fourties_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total =round(n/sum(n), digits=2))

fourties_sentiments <- fourties_sentiments %>%
  mutate(percent = percent(pct_total)) %>%
  mutate(decade = "Fourties")

#fifties
fifties_text <- articles_text %>% 
  filter((round(year / 10) * 10) == 1950)

fifties_text_tokenized <- fifties_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

fifties_sentiments <- fifties_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total =round(n/sum(n), digits=2))

fifties_sentiments <- fifties_sentiments %>%
  mutate(percent = percent(pct_total)) %>%
  mutate(decade = "Fifties")

#sixties
sixties_text <- articles_text %>% 
  filter((round(year / 10) * 10) == 1960)

sixties_text_tokenized <- sixties_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

sixties_sentiments <- sixties_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total =round(n/sum(n), digits=2))

sixties_sentiments <- sixties_sentiments %>%
  mutate(percent = percent(pct_total)) %>%
  mutate(decade = "Sixties")

decade_sentiment_all <- fourties_sentiments %>%
  bind_rows(fifties_sentiments %>% bind_rows(sixties_sentiments))

ggplot(decade_sentiment_all, aes(sentiment, percent, fill=decade)) +
  geom_bar(stat="identity", position="dodge") +
  labs(title = "Presence of Sentiment in Articles by Raymond Moley, Grouped by Decade",
        x = "Sentiment",
        y = "Percentage of Total Text") + 
  theme(axis.text.x = element_text(angle = 45, vjust=0.5)) + 
  scale_fill_manual(values = c("orange", "purple", "navy"))

```



## Economic vs Political Articles Over Time


I generated the lists to determine economic and political articles using ChatGPT, giving it the following prompts. 

### For economic words:

"Give me a list of words in the english language that have an economic connotation."
"Add the words economy, economic, money, and union"
```{r echo = F}

economic_terms <- read.csv("./data/Economic_Terms.csv")
kable(head(economic_terms, 20), caption="Sample of Economic Terms")

```
### For political words:

"Give me a list of words in the English language that have a political connotation specific to the years 1932-1960 but also general political terms. Specific to american politics."
  
```{r echo = F}

political_terms <- read.csv("./data/Political_Terms.csv")
kable(head(political_terms, 20), caption="Sample of Political Terms")

```
#Unigrams
```{r}

unigrams <- articles_text %>% mutate(sentence= str_squish(sentence)) |> 
  mutate(text = tolower(sentence)) |>  
  mutate(text = gsub("\\d+", "", text)) |>
  mutate(text = str_replace_all(text, "raymond", "")) %>% 
  mutate(text = str_replace_all(text, "newsweek", "")) %>% 
  mutate(text = str_replace_all(text, "image", "")) %>%
  mutate(text = str_replace_all(text, "perspective", "")) %>%
  mutate(text = str_replace_all(text, "registered u.s. patent office", "")) %>%
  mutate(text = str_replace_all(text, "- ", "")) %>%
  mutate(text = str_replace_all(text, " -", "")) %>%
  mutate(text = str_replace_all(text, " - ", "")) %>%
  unnest_tokens(word, text, token="ngrams", n=1 ) %>%
  filter(!word %in% stop_words$word) %>%
  filter(!word == "minor inaccuracies") %>%
  filter(!word == "text extraction") %>%
  filter(!word == "text version") %>%
    filter(!is.na(word))



one_word_per_row <- unigrams |> 
  select(word, date, year, filename)

```

#Chart Political vs Economic Coverage
```{r}
count_word_per_year <- function(data, target_word) {
  data %>%
    filter(word == target_word) %>%       
    group_by(year) %>%                   
    summarise(count = n(), .groups = "drop") 
}

political_articles <- one_word_per_row %>%
  select(filename, year, word) %>%
  filter(word %in% political_terms$Word )

political_articles <- political_articles %>%
  select(filename, year)

political_articles <- distinct(political_articles)

economic_articles <- one_word_per_row %>%
  select(filename, year, word) %>%
  filter(word %in% economic_terms$Word )

economic_articles <- economic_articles %>%
   select(filename, year)

economic_articles <- distinct(economic_articles)

both_econ_political <- political_articles %>%
  select(filename, year) %>%
  filter(filename %in% economic_articles$filename)

only_political <- political_articles %>%
  select(filename, year) %>%
  filter(!filename %in% economic_articles$filename)

only_economic <- economic_articles %>%
  select(filename, year) %>%
  filter(!filename %in% political_articles$filename)

political_articles_by_year <- political_articles %>%
  count(year) %>%
  group_by(year)

political_articles_by_year <- political_articles_by_year %>%
  mutate(type = "political")

economic_articles_by_year <- economic_articles %>%
  count(year) %>%
  group_by(year)

economic_articles_by_year <- economic_articles_by_year %>%
  mutate(type = "economic")

article_type_by_year <- economic_articles_by_year %>%
  bind_rows(political_articles_by_year)

ggplot(article_type_by_year, aes(year, n, fill=type)) +
  geom_bar(stat="identity", position="dodge") + 
  labs(title = "Political vs. Economic Articles Written by Raymond Moley, 1937-1967",
        x = "Year",
        y = "Count",
       caption= "n=1,487 Newsweek columns. Graphic by Bridget Lang, 2/16/2025")

```


## Topic Model 

For some reason the graph below is turning gray. I get the message "Scale for fill is already present. Adding another scale for fill, which will replace the existing scale." when I try to load it, and also trying to load the graph in the topic model sample exercise. I am not sure what to do, looking online did not help. I am uploading a screenshot of the graph here: https://github.com/blangumd/CompText_Jour_FinalProject/blob/main/topic_model_vis.png

```{r echo = F, results = 'hide', error=F, warning=F, message=F}
topics <- read.csv("./data/topics.csv")

kable(topics, caption="Topics")

vizDataFrame <- read.csv("./data/vizDataFrame.csv")

ggplot(vizDataFrame, aes(x=decade, y=value, fill=category)) + 
  geom_bar(stat = "identity") + ylab("proportion") + 
  scale_fill_manual(values = paste0(alphabet(20), "FF"), name = "decade") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
   scale_fill_manual(values=c("#9933FF",
                              "#33FFFF",
                              "red",
                              "yellow",
                              "darkblue",
                              "green"))+
   #                           "blue"))+ 
   #                           #"pink",
   #                           #"gray",
   #                           #"orange")) +
  labs(title = "Common Narratives in Raymond Moley's Reporting")
```

## Sample Codes 

**federal government** - Anything descriptive about the federal government in terms of entity or location

**economic policy** - Describing or critiquing policy, habits, or status of the economy and any specific person's interactions or influence on it. 

**commentary** - Any statements of clear opinion, not based or citing of facts. 

**election** - Relating to or commenting on an ongoing, past, or future election, its candidates, its status, and/or expected or hoped-for outcome.

## Background on Raymond Moley

Born in 1886, Raymond Moley was an American journalist, presidential advisor, and political economist. He is well known as a founder of the "Brain Trust", which was Roosovelt's group of advisors during his campaign in 1932. This group helped pen the New Deal, which was a group of controversial policy measures passed by Roosovelt to help aid in recovery from the great depression. Moley was a outspoken supporter of the New Deal early in his work with FDR, but as the presidency continued, his opinions began to shift and he ended up becoming one of its largest critics. He used his platform as a political columnist to advise and provide insight on what he believed to be the successes and issues within the political climate of his time. 

https://case.edu/ech/articles/m/moley-raymond
https://www.britannica.com/biography/Raymond-Charles-Moley
https://www.presidency.ucsb.edu/documents/remarks-presenting-the-presidential-medal-freedom-eight-journalists
https://www.britannica.com/event/New-Deal



## Bridget's Essay
The data itself is currently a collection of 105 articles, written by Raymond Moley for Newsweek between the years 1942 and 1960. For each article there is a known filename, length, and date of publication, along with the contents of each article. There were a few iterations of importing data before a final process and dataset was established. The issue mainly lied in the way that the articles needed to be scanned, as the format was columns, which are difficult for a usual PDF scanning software to decipher. Dr. Wells used a variety of methods, including artififical intelligence, to gather these articles and put them into a final set of 105 articles with an accompanying index. All but one of the articles written in 1948 were corrupted, showing up as lines of "[?]" rather than text. The cause of this issue is unknown, but it is interesting that it was all articles from 1948. I excluded the one functional article from 1948 in order to prevent the data being skewed in any analysis done based on year or decade. 

I created a table of the top 20 bigrams, the two most common of which being "republican party" and "federal government". This is not a surprise given that Moley was an advisor for every republican presidential candidate from 1934-1960. The second most common after these two bigram was "democratic party", followed by "vice president", then "federal aid". I think that "federal aid" is the first bigram of significant interest, given that the first four are no surprise given the context of the writing. "Federal aid" implies discussion of policy or use of government funds, which was likely a common theme for Moley's writings. 

Note that Goldwater's election is outside the range of these articles so there is no coverage of him. He virtually advised every republican presidential candidate from 1942-1964, while also maintaining his role as a political columnist for Newsweek. His duel role in political journalism and political advising makes his reporting particularly interesting to look at, specifically his coverage of the candidates he associated with and the sentiment of this coverage. Moley first covered Thomas Dewey in October 1942, which is two years before Dewey took office for the first time. #rsw comment: not the case but I understand the data shows this. Moley first covered Nixon in May 1960, which is the same year that Moley was an acting adviser for Nixon. For words with a generally encouraging connotation, such as joy, anticipation, trust, positive, were used to describe Nixon rather than Dewey. We can also see that words with a generally discouraging connotation, such as negative, fear, anger, and disgust, were used to describe Dewey at a higher rate than to describe Nixon. This shows a clear distinction between how Moley referred to both men in his writing, and that he had a clear bias toward Nixon.

Both figures had the same four most common sentiments, which are "positive", "trust", "negative", and then "anticipation". However, in comparing the sentiment analyses of coverage on Nixon vs. coverage on Dewey, there is a clear difference in the attitude and tone that Moley used for each president. For example, in an article Moley wrote in 1950, he states that "Richard Nixon, a young, aggressive, and attractive conservative, will get the Republican nomination almost unopposed." This statement is a clear statement of not only support for Nixon but anticipation that he is going to win the nomination. In contrast, he wrote about Dewey that "disaster befell Thomas E. Dewey in 1948 because his great confidence in polls shaped his carefree, "it's-in-the-bag" campaign. But at the moment nothing so occupies the attention of several putative Presidential candidates as polls." He describes Dewey's attitudes about the election in a almost mocking manner, impLying that his confidence is unfounded and not helpful. 

In an analysis looking at the number of political vs. economic articles, there were few articles that could be categorized as strictly one or the other. However, in the graph titled "Political vs. Economic Articles Written by Raymond Moley, 1942-1960", it is clear that there was a slight increase in economic articles written between 1953-1960. Although this skew may be due to a higher number of articles in the dataset written within these years, it is interesting to consider what in history during this time may cause this increase in economic themes of Moley's writing. 

The final form of analysis I conducted was a topic model, with k=6 categories generated. It is important to note that there was a category generated of meta data such as the names of articles and the publication that would have been very tedious to remove via code. Thus, there are only five categories that really say much about the themes and narratives of Moley's reporting. The topic that I found the most intriguing was the one I labeled "american_ideals", which included words like "men" and "economy".



