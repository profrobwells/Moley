---
title: "Content Analysis of Raymond Moleyâ€™s Reporting from 1937 - 1968"
author: "Rob Wells and Bridget Lang"
date: '2025-2-14'
output: html_document
---

This project aims to perform a basic narrative and topic analysis of the journalism of **Raymond Moley**, a prominent columnist who advocated a centrist conservative political vision from 1937 through 1967 in his books, weekly Newsweek column and syndicated newspaper column. 

The goal of this project is to **measure patterns in wording, verbiage, themes, and sentiment** of Raymond Moley's poltitical reporting over time. This research will support a larger effort in analyzing the **influence of journalism and polticial activism on American elections, voting, and democracy at large**. 

I am focusing on the time period of Moley's work from **1937-1968**, with **1400 articles**  analyzed. 

The index has 1562 articles
The earliest year of publication is 1937, and the latest is 1967.
The average year of publication is 1952, with the majority of articles written in 1938.
The article text has 1487 articles. That's less than the 1562 entries in the article index. The difference was due to about 75 failed AI scans.

## Background on Raymond Moley

Born in 1886, Raymond Moley was an American journalist, presidential advisor, and political economist. He is well known as a founder of the "Brain Trust", which was Roosovelt's group of advisors during his campaign in 1932. This group helped pen the New Deal, which was a group of controversial policy measures passed by Roosovelt to help aid in recovery from the great depression. Moley was a outspoken supporter of the New Deal early in his work with FDR, but as the presidency continued, his opinions began to shift and he ended up becoming one of its largest critics. He used his platform as a political columnist to advise and provide insight on what he believed to be the successes and issues within the political climate of his time. 

https://case.edu/ech/articles/m/moley-raymond
https://www.britannica.com/biography/Raymond-Charles-Moley
https://www.presidency.ucsb.edu/documents/remarks-presenting-the-presidential-medal-freedom-eight-journalists
https://www.britannica.com/event/New-Deal


## Libraries Used

Some of these libraries are used only in this webpage, but this is all libraries used in the analysis done so far. 

```{r echo = T, results = 'hide', error=F, warning=F, message=F}


library(textdata)
library(tidyverse)
library(pdftools)
library(dplyr)
library(rio)
library(tidytext)
library(quanteda)
library(knitr)
library(formattable)
library(forcats)
library(readtext)
#topic modeling
library(tm)
library(topicmodels)
library(lda)
library(ldatuning)
# from tutorial packages
library(DT)
library(knitr) 
library(kableExtra) 
library(reshape2)
library(ggplot2)
library(wordcloud)
library(pals)
library(SnowballC)
library(flextable)
library(janitor)
```

## Statistics about the data 
```{r echo = F}
#1562 articles in index
article_index <-  rio::import("matching with extract-Perspective_full_index_1967_1937.xls") |> 
  clean_names() |> 
  mutate(year = as.numeric(year),
         date = as.Date(pubdate, format="%b %d, %Y"))

#136596 rows of text
articles_text <-  read_csv("/Users/gizmofo/Library/CloudStorage/Dropbox/Current_Projects/Moley project 2024/moley_cleaned_perspective_text.csv") |> 
    mutate(year = as.numeric(year),
         date = as.Date(pubdate, format="%b %d, %Y"))

nrows <- nrow(article_index)
ncols <- ncol(article_index)

mean_year <- round(mean(article_index$year, na.rm = TRUE),0)

min_year <- min(article_index$year)

max_year <- max(article_index$year)


year_counts <- 
  article_index %>%
  count(year)

max_count <- max(year_counts$n)
max_years <- year_counts %>%
  select(year) %>%
  filter(year_counts$n == max_count)
                  

glue::glue("There are {nrows} articles");

glue::glue("The earliest year of publication is {as.integer(min_year)}, and the latest is {max_year}.")

glue::glue("The average year of publication is {as.integer(mean_year)}, with the majority of articles written in {max_years$year}.")




```

## Columns and Rows
```{r echo = F}
nrows1 <- nrow(articles_text)
ncols1 <- ncol(articles_text)

articles <- articles_text |> 
  distinct(filename) |> 
  count()

glue::glue("The number of rows in the article text dataframe is {nrows1}")
glue::glue("The number of article text columns is {ncols1}")
glue::glue("The article text has {articles} articles. That's less than the {nrows} entries in the article index. The difference was due to about {nrows-articles} failed AI scans.")

```


# Figure x: Articles over time

```{r}

#Here is a chart, Figure x, that countss columns by year
count_year <- articles_text %>% 
  distinct(filename, .keep_all = TRUE) |> 
count(year) %>% 
#Sandwich it onto a simple ggplot
  ggplot(aes(x = year, y = n, fill = n)) +
  geom_col(position = "dodge") + 
  theme(legend.position = "none") +
  scale_x_continuous(breaks = seq(1935, 1970, by = 5))+
  labs(title = "Moley Newsweek Columns By Year, 1937-1967", 
       subtitle = "Extracted Text Only",
       caption = "n=1,487  articles. Graphic by Rob Wells, 2/14/2025",
       y="Count of Pages",
       x="Year")

count_year

#ggsave(here::here("Figure_X_ columns_by_year_2_14_2025.png"),device = "png",width=9,height=6, dpi=800)

```


# Bigrams
```{r}
bigrams <- articles_text %>% mutate(sentence= str_squish(sentence)) |> 
  mutate(text = tolower(sentence)) |>  
  mutate(text = gsub("\\d+", "", text)) |>
  mutate(text = str_replace_all(text, "raymond", "")) %>% 
  mutate(text = str_replace_all(text, "newsweek", "")) %>% 
  mutate(text = str_replace_all(text, "image", "")) %>%
  mutate(text = str_replace_all(text, "perspective", "")) %>%
  mutate(text = str_replace_all(text, "registered u.s. patent office", "")) %>%
  mutate(text = str_replace_all(text, "- ", "")) %>%
  mutate(text = str_replace_all(text, " -", "")) %>%
  mutate(text = str_replace_all(text, " - ", "")) %>%
  unnest_tokens(word, text, token="ngrams", n=2 ) %>%
  filter(!word %in% stop_words$word) %>%
  filter(!word == "minor inaccuracies") %>%
  filter(!word == "text extraction") %>%
  filter(!word == "text version") %>%
    filter(!is.na(word))

bigrams <- bigrams %>%
  select(word, date, year, filename)

```

# Cleaning bigrams
```{r}
bigrams_separated <- bigrams %>%
  separate(word, c("word1", "word2"), sep = " ")

#bigrams with stop words filtered

bigrams_filtered <- 
  bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

bigram_counts <- bigrams_filtered %>%
  count(word1, word2, sort = TRUE) %>% 
  filter(!is.na(word1))

datatable(bigram_counts,
          caption = "Top Bigrams",
          options = list(pageLength = 20))

```


```{r}
  
top_20_bigrams <- bigram_counts |> 
   top_n(20) |> 
  mutate(bigram = paste(word1, " ", word2)) |> 
  select(bigram, n)

ggplot(top_20_bigrams, aes(n, reorder(bigram, n), fill=n)) +
  geom_bar(stat="identity", position="dodge") +
  theme(legend.position="none") +
  geom_text(aes(label=n), hjust=-0.2, size=3) +
  labs(title = "Raymond Moley Common Phrases, 1937-1967",
       subtitle = "Analysis of 1,487 Newsweek columns",
       x = "Count",
       y = "Bigrams",
       caption = "Source: Newsweek. Graphic by Rob Wells and Bridget Lang, 2-14-2024")
```




## Economic vs Political Articles Over Time


I generated the lists to determine economic and political articles using ChatGPT, giving it the following prompts. 

### For economic words:

"Give me a list of words in the english language that have an economic connotation."
"Add the words economy, economic, money, and union"
```{r echo = F}

economic_terms <- read.csv("./data/Economic_Terms.csv")
kable(head(economic_terms, 20), caption="Sample of Economic Terms")

```
### For political words:

"Give me a list of words in the English language that have a political connotation specific to the years 1932-1960 but also general political terms. Specific to american politics."
  
```{r echo = F}

political_terms <- read.csv("./data/Political_Terms.csv")
kable(head(political_terms, 20), caption="Sample of Political Terms")

```
#rsw comment: this was a cool and basic way to begin the analysis. Nice job and a creative, simple solution.
```{r echo = F}
one_word_per_row <- read.csv("./data/one_word_per_row.csv")

count_word_per_year <- function(data, target_word) {
  data %>%
    filter(word == target_word) %>%       
    group_by(year) %>%                   
    summarise(count = n(), .groups = "drop") 
}

political_articles <- one_word_per_row %>%
  select(filename, year, word) %>%
  filter(word %in% political_terms$Word )

political_articles <- political_articles %>%
  select(filename, year)

political_articles <- distinct(political_articles)

economic_articles <- one_word_per_row %>%
  select(filename, year, word) %>%
  filter(word %in% economic_terms$Word )

economic_articles <- economic_articles %>%
   select(filename, year)

economic_articles <- distinct(economic_articles)

both_econ_political <- political_articles %>%
  select(filename, year) %>%
  filter(filename %in% economic_articles$filename)

only_political <- political_articles %>%
  select(filename, year) %>%
  filter(!filename %in% economic_articles$filename)

only_economic <- economic_articles %>%
  select(filename, year) %>%
  filter(!filename %in% political_articles$filename)

political_articles_by_year <- political_articles %>%
  count(year) %>%
  group_by(year)

political_articles_by_year <- political_articles_by_year %>%
  mutate(type = "political")

economic_articles_by_year <- economic_articles %>%
  count(year) %>%
  group_by(year)

economic_articles_by_year <- economic_articles_by_year %>%
  mutate(type = "economic")

article_type_by_year <- economic_articles_by_year %>%
  bind_rows(political_articles_by_year)

ggplot(article_type_by_year, aes(year, n, fill=type)) +
  geom_bar(stat="identity", position="dodge") + 
  labs(title = "Political vs. Economic Articles Written by Raymond Moley, 1942 - 1960",
        x = "Year",
        y = "Count")

```

## Sentiment Analysis of Coverage of Presidential Candidates 
#rsw comment: nice way to begin the analysis.  
```{r echo = F}

articles_text <- rename(articles_text, sentence = value)

nixon_articles <- articles_text %>%
  filter(str_detect(sentence, "Nixon")) %>%
  select(filename, year) %>%
  distinct(filename, year)

goldwater_articles <- articles_text %>%
  filter(str_detect(sentence, "Goldwater")) %>%
  select(filename, year) %>%
  distinct(filename, year)

roosevelt_articles <- articles_text %>%
  filter(str_detect(sentence, "Roosevelt")) %>%
  select(filename, year) %>%
  distinct(filename, year)

dewey_articles <- articles_text %>%
  filter(str_detect(sentence, "Dewey")) %>%
  select(filename, year) %>%
  distinct(filename, year)


nrc_sentiments <- get_sentiments("nrc")
afinn_sentiments <- get_sentiments("afinn")

```

### Dewey

```{r echo = F, results = 'hide', error=F, warning=F, message=F}

dewey_text <- articles_text %>%
  select(filename, year, sentence) %>%
  filter(filename %in% dewey_articles$filename)


dewey_text_tokenized <- dewey_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

dewey_sentiments_all <- dewey_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total =round(n/sum(n), digits=2))

dewey_sentiments_all <- dewey_sentiments_all %>%
  mutate(percent = percent(pct_total)) %>%
  mutate(president = "Dewey")


dewey_sentiments_all <- dewey_sentiments_all %>%
  mutate(sentiment = fct_reorder(sentiment, desc(percent)))

ggplot(dewey_sentiments_all, aes(sentiment, percent, fill=president)) +
  geom_bar(stat="identity", position="dodge") +
  labs(title = "Presence of Sentiment in Articles by Raymond Moley Mentioning Thomas Dewey",
        x = "Sentiment",
        y = "Percentage of Total Text") + 
  theme(axis.text.x = element_text(angle = 45, vjust=0.5)) 


```

### Nixon

```{r echo = F, results = 'hide', error=F, warning=F, message=F}

nixon_text <- articles_text %>%
  select(filename, year, sentence) %>%
  filter(filename %in% nixon_articles$filename)

nixon_text_tokenized <- nixon_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

nixon_sentiments_all <- nixon_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total =round(n/sum(n), digits=2))

nixon_sentiments_all <- nixon_sentiments_all %>%
  mutate(percent = percent(pct_total)) %>%
  mutate(president = "Nixon")

nixon_sentiments_all <- nixon_sentiments_all %>%
  mutate(sentiment = fct_reorder(sentiment, desc(percent)))

ggplot(nixon_sentiments_all, aes(sentiment, percent, fill=president)) +
  geom_bar(stat="identity", position="dodge") +
  labs(title = "Presence of Sentiment in Articles by Raymond Moley Mentioning Richard Nixon",
        x = "Sentiment",
        y = "Percentage of Total Text") + 
  theme(axis.text.x = element_text(angle = 45, vjust=0.5)) 


```

### Comaprison
#rsw comment - This is very cool, extremely helpful for what I am doing. A few tweaks: the y axis needs to be properly formatted in percents. You write these bomber headlines that go off the margins, so tighten that up
```{r echo = F, results = 'hide', error=F, warning=F, message=F}

nixon_dewey_sentiments <- dewey_sentiments_all %>%
  bind_rows(nixon_sentiments_all)

ggplot(nixon_dewey_sentiments, aes(sentiment, percent, fill=president)) +
  geom_bar(stat="identity", position="dodge") +
  labs(title = "Presence of Sentiment in Articles by Raymond Moley Mentioning Richard Nixon vs. Thomas Dewey",
        x = "Sentiment",
        y = "Percentage of Total Text") + 
  theme(axis.text.x = element_text(angle = 45, vjust=0.5)) + 
  scale_fill_manual(values = c("forestgreen", "purple"))



```

# Wells fix  
```{r echo = F, results = 'hide', error=F, warning=F, message=F}

nixon_dewey_sentiments <- dewey_sentiments_all %>%
  bind_rows(nixon_sentiments_all)

ggplot(nixon_dewey_sentiments, aes(sentiment, percent, fill=president)) +
  geom_bar(stat="identity", position="dodge") +
  scale_y_continuous(labels = scales::percent)+
  labs(title = "Moley Sentiment Nixon vs. Dewey",
       subtitle = "Analysis of Newsweek columns, 1942-1960",
       caption = "Graphic by Bridget Lang, 12-10-2024",
        x = "Sentiment",
        y = "Percentage of Total Text") + 
  theme(axis.text.x = element_text(angle = 45, vjust=0.5)) + 
  scale_fill_manual(values = c("forestgreen", "purple"))



```

## Overall Sentiment Analysis 

### All Articles
#rsw comment - again, fix the y axis to scale as percentages. 
```{r echo = F, results = 'hide', error=F, warning=F, message=F}

all_text_tokenized <- articles_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

sentiments_all <- all_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total =round(n/sum(n), digits=2))

sentiments_all <- sentiments_all %>%
  mutate(percent = percent(pct_total)) %>%
  mutate(sentiment = fct_reorder(sentiment, desc(percent)))

ggplot(sentiments_all, aes(sentiment, percent, fill=percent)) +
  geom_bar(stat="identity", position="dodge") +
  labs(title = "Presence of Sentiment in Articles by Raymond Moley, 1942-1964",
        x = "Sentiment",
        y = "Percentage of Total Text")

```

### By Decade

#rsw comment; great idea. the bars need to be in chronological sequence, though. An easier way would be to mutate a new decade variable and visualize that instead.
```{r echo = F, results = 'hide', error=F, warning=F, message=F}
#fourties
fourties_text <- articles_text %>% 
  filter((round(year / 10) * 10) == 1940)

fourties_text_tokenized <- fourties_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

fourties_sentiments <- fourties_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total =round(n/sum(n), digits=2))

fourties_sentiments <- fourties_sentiments %>%
  mutate(percent = percent(pct_total)) %>%
  mutate(decade = "Fourties")

#fifties
fifties_text <- articles_text %>% 
  filter((round(year / 10) * 10) == 1950)

fifties_text_tokenized <- fifties_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

fifties_sentiments <- fifties_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total =round(n/sum(n), digits=2))

fifties_sentiments <- fifties_sentiments %>%
  mutate(percent = percent(pct_total)) %>%
  mutate(decade = "Fifties")

#sixties
sixties_text <- articles_text %>% 
  filter((round(year / 10) * 10) == 1960)

sixties_text_tokenized <- sixties_text %>% 
  select(sentence) %>% 
  mutate(sentence = str_replace_all(sentence, "- ", "")) %>% 
  unnest_tokens(word, sentence) %>% 
  filter(!word %in% stop_words$word) %>% 
  filter(!grepl('[0-9]', word))

sixties_sentiments <- sixties_text_tokenized %>%
  inner_join(nrc_sentiments, relationship = "many-to-many") %>%
  count(sentiment, sort = TRUE) %>% 
  mutate(pct_total =round(n/sum(n), digits=2))

sixties_sentiments <- sixties_sentiments %>%
  mutate(percent = percent(pct_total)) %>%
  mutate(decade = "Sixties")

decade_sentiment_all <- fourties_sentiments %>%
  bind_rows(fifties_sentiments %>% bind_rows(sixties_sentiments))

ggplot(decade_sentiment_all, aes(sentiment, percent, fill=decade)) +
  geom_bar(stat="identity", position="dodge") +
  labs(title = "Presence of Sentiment in Articles by Raymond Moley, Grouped by Decade",
        x = "Sentiment",
        y = "Percentage of Total Text") + 
  theme(axis.text.x = element_text(angle = 45, vjust=0.5)) + 
  scale_fill_manual(values = c("orange", "purple", "navy"))

```

## Topic Model 

For some reason the graph below is turning gray. I get the message "Scale for fill is already present. Adding another scale for fill, which will replace the existing scale." when I try to load it, and also trying to load the graph in the topic model sample exercise. I am not sure what to do, looking online did not help. I am uploading a screenshot of the graph here: https://github.com/blangumd/CompText_Jour_FinalProject/blob/main/topic_model_vis.png

```{r echo = F, results = 'hide', error=F, warning=F, message=F}
topics <- read.csv("./data/topics.csv")

kable(topics, caption="Topics")

vizDataFrame <- read.csv("./data/vizDataFrame.csv")

ggplot(vizDataFrame, aes(x=decade, y=value, fill=category)) + 
  geom_bar(stat = "identity") + ylab("proportion") + 
  scale_fill_manual(values = paste0(alphabet(20), "FF"), name = "decade") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
   scale_fill_manual(values=c("#9933FF",
                              "#33FFFF",
                              "red",
                              "yellow",
                              "darkblue",
                              "green"))+
   #                           "blue"))+ 
   #                           #"pink",
   #                           #"gray",
   #                           #"orange")) +
  labs(title = "Common Narratives in Raymond Moley's Reporting")
```

## Sample Codes 

**federal government** - Anything descriptive about the federal government in terms of entity or location

**economic policy** - Describing or critiquing policy, habits, or status of the economy and any specific person's interactions or influence on it. 

**commentary** - Any statements of clear opinion, not based or citing of facts. 

**election** - Relating to or commenting on an ongoing, past, or future election, its candidates, its status, and/or expected or hoped-for outcome.

## Essay
The data itself is currently a collection of 105 articles, written by Raymond Moley for Newsweek between the years 1942 and 1960. For each article there is a known filename, length, and date of publication, along with the contents of each article. There were a few iterations of importing data before a final process and dataset was established. The issue mainly lied in the way that the articles needed to be scanned, as the format was columns, which are difficult for a usual PDF scanning software to decipher. Dr. Wells used a variety of methods, including artififical intelligence, to gather these articles and put them into a final set of 105 articles with an accompanying index. All but one of the articles written in 1948 were corrupted, showing up as lines of "[?]" rather than text. The cause of this issue is unknown, but it is interesting that it was all articles from 1948. I excluded the one functional article from 1948 in order to prevent the data being skewed in any analysis done based on year or decade. 

I created a table of the top 20 bigrams, the two most common of which being "republican party" and "federal government". This is not a surprise given that Moley was an advisor for every republican presidential candidate from 1934-1960. The second most common after these two bigram was "democratic party", followed by "vice president", then "federal aid". I think that "federal aid" is the first bigram of significant interest, given that the first four are no surprise given the context of the writing. "Federal aid" implies discussion of policy or use of government funds, which was likely a common theme for Moley's writings. 

Note that Goldwater's election is outside the range of these articles so there is no coverage of him. He virtually advised every republican presidential candidate from 1942-1964, while also maintaining his role as a political columnist for Newsweek. His duel role in political journalism and political advising makes his reporting particularly interesting to look at, specifically his coverage of the candidates he associated with and the sentiment of this coverage. Moley first covered Thomas Dewey in October 1942, which is two years before Dewey took office for the first time. #rsw comment: not the case but I understand the data shows this. Moley first covered Nixon in May 1960, which is the same year that Moley was an acting adviser for Nixon. For words with a generally encouraging connotation, such as joy, anticipation, trust, positive, were used to describe Nixon rather than Dewey. We can also see that words with a generally discouraging connotation, such as negative, fear, anger, and disgust, were used to describe Dewey at a higher rate than to describe Nixon. This shows a clear distinction between how Moley referred to both men in his writing, and that he had a clear bias toward Nixon.

Both figures had the same four most common sentiments, which are "positive", "trust", "negative", and then "anticipation". However, in comparing the sentiment analyses of coverage on Nixon vs. coverage on Dewey, there is a clear difference in the attitude and tone that Moley used for each president. For example, in an article Moley wrote in 1950, he states that "Richard Nixon, a young, aggressive, and attractive conservative, will get the Republican nomination almost unopposed." This statement is a clear statement of not only support for Nixon but anticipation that he is going to win the nomination. In contrast, he wrote about Dewey that "disaster befell Thomas E. Dewey in 1948 because his great confidence in polls shaped his carefree, "it's-in-the-bag" campaign. But at the moment nothing so occupies the attention of several putative Presidential candidates as polls." He describes Dewey's attitudes about the election in a almost mocking manner, impLying that his confidence is unfounded and not helpful. 

In an analysis looking at the number of political vs. economic articles, there were few articles that could be categorized as strictly one or the other. However, in the graph titled "Political vs. Economic Articles Written by Raymond Moley, 1942-1960", it is clear that there was a slight increase in economic articles written between 1953-1960. Although this skew may be due to a higher number of articles in the dataset written within these years, it is interesting to consider what in history during this time may cause this increase in economic themes of Moley's writing. 

The final form of analysis I conducted was a topic model, with k=6 categories generated. It is important to note that there was a category generated of meta data such as the names of articles and the publication that would have been very tedious to remove via code. Thus, there are only five categories that really say much about the themes and narratives of Moley's reporting. The topic that I found the most intriguing was the one I labeled "american_ideals", which included words like "men" and "economy".



