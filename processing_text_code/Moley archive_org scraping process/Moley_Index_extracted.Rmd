---
title: "Moley Index"
author: "Rob Wells"
date: "2024-12-04"
output: html_document
---

```{r}
library(tidyverse)
```


This rationalizes the index for the extracted articles

```{r}

#Import spreadsheet of Newsweek back issues

newsweek <- rio::import("newsweek_sample_size.xlsx", sheet="newsweek_index_37_61")
```

create year column

```{r}
newsweek <- newsweek %>%
  mutate(
    date = str_extract(identifier, "\\d{4}-\\d{2}-\\d{2}"),
    volume = str_extract(identifier, "_\\d+_") %>% str_remove_all("_") %>% as.integer(),
    issue = str_extract(identifier, "_\\d+$") %>% str_remove_all("_") %>% as.integer(),
    year = as.numeric(str_extract(identifier, "19\\d{2}"))
  )

```

222 articles from 1950s
```{r}
index_1950s_cleaned <- read.csv("cleaned_moley_1950s_index.csv")
```


Index of 23 extracted articles
```{r}
AI_extracted <- read.csv("~/Code/Moley/extracted_AI_moley_index_nov_20.csv")
#these articles will match on sequence
```

Build index and rename files for AI_extracted
```{r}
AI_extracted_files <- list.files("./AI_extracted", pattern="*.txt") %>% 
  as.data.frame() |> 
  rename(filename = 1) |> 
  #create an index with the file name
 mutate(file_number = str_extract(filename, "\\d+")) |> 
  mutate(file_number = as.numeric(file_number)) |> 
  mutate(index = row_number())

```

Rename files in AI_extracted
```{r}
# Path to your folder
folder_path <- "./AI_extracted"

# Get a tibble of files in the folder
files <- tibble(
  original_path = dir(folder_path, full.names = TRUE),
  original_name = dir(folder_path)
)

files <- files |> 
  inner_join(AI_extracted, c("original_name" = "filename"))

# Add the new file names based on the `article` index
renamed_files <- files %>%
  mutate(
    # article = paste0("article_", row_number()), # Generate article index
    new_name = paste0(list, ".txt"),         # Add desired extension
    new_path = file.path(folder_path, new_name) # Full path for new names
  )

# Rename the files using purrr::walk2
walk2(
  renamed_files$original_path,
  renamed_files$new_path,
  ~ file.rename(.x, .y) # .x = old file path, .y = new file path
)

# Check results
print(renamed_files)

```


Index of 19 extracted articles
```{r}
AI2_extracted <- read.csv("retry_scans_nov_25.csv")
#these articles will match on index
```


```{r}
# Build index and rename files for AI_extracted
AI2_extracted_files <- list.files("./AI2_extracted", pattern="*.txt") %>% 
  as.data.frame() |> 
  rename(filename = 1) |> 
  #create an index with the file name
 mutate(file_number = str_extract(filename, "\\d+")) |> 
  mutate(file_number = as.numeric(file_number)) |> 
  mutate(index = row_number())
```

join indexes with file list
```{r}
AI2_extracted_filtered <- AI2_extracted |> 
  inner_join(AI2_extracted_files, by=c("X"="file_number"))

```


Rename files in AI2_extracted
```{r}
# Path to your folder
folder_path <- "./AI2_extracted"

# Get a tibble of files in the folder
files <- tibble(
  original_path = dir(folder_path, full.names = TRUE),
  original_name = dir(folder_path)
)

files <- files |> 
  inner_join(AI2_extracted_filtered, c("original_name" = "filename"))

# Add the new file names based on the `article` index
renamed_files <- files %>%
  mutate(
    # article = paste0("article_", row_number()), # Generate article index
    new_name = paste0(list, ".txt"),         # Add desired extension
    new_path = file.path(folder_path, new_name) # Full path for new names
  )

# Rename the files using purrr::walk2
walk2(
  renamed_files$original_path,
  renamed_files$new_path,
  ~ file.rename(.x, .y) # .x = old file path, .y = new file path
)

# Check results
print(renamed_files)
```

# create master list of AI extracted articles

```{r}
x <- AI_extracted |> 
  select(column2, list, date2, Year, real_page, URL) |> 
  rename(page = real_page, date=date2) |> 
  mutate(date = ymd(date)) |> 
  mutate(date = if_else(year(date) > 1999, date - years(100), date)) |> 
  mutate(date = as.Date(date, "%Y/%m/%d"))

y <- AI2_extracted_filtered |> 
  select(column2, list, date_new, Year, page, URL) |> 
  rename(date = date_new) |> 
  mutate(date = mdy(date)) |> 
  mutate(date = if_else(year(date) > 1999, date - years(100), date)) |> 
  mutate(date = as.Date(date, "%Y/%m/%d"))


combined_AI_extracted <- rbind(x,y)


folder_path <- "./AI_extracted_all"

combined_AI_extracted <- combined_AI_extracted %>%
  mutate(
    new_name = paste0(list, ".txt"),         # Add desired extension
    new_path = file.path(folder_path, new_name) # Full path for new names
  )

# write.csv(combined_AI_extracted, "./AI_extracted_all/combined_AI_extracted.csv")
```

one time Fix volume and issue
```{r}

combined_AI_extracted  <- combined_AI_extracted |> 
  mutate(
  volume = str_extract(new_name, "_\\d+_") %>% str_remove_all("_") %>% as.integer(),
   issue = str_extract(new_name, "_\\d+\\.txt$") %>% str_remove_all("_|\\.txt")) 

#write.csv(combined_AI_extracted, "./AI_extracted_all/moley_extracted_index.csv")
```


# Build Index from main articles

```{r}

older_articles <- list.files("~/Code/CompText_Jour/code/Moley_for_students/moley_newsweek", pattern="*.txt") %>% 
  as.data.frame() |> 
  rename(filename = 1) |> 
  mutate(date = str_extract(filename, "\\d{4}-\\d{2}-\\d{2}")) |> 
  inner_join(newsweek, c=("date"))
  
 

```


# Rename files in older-articles
```{r}
# Path to your folder
folder_path <- "./older_articles"

# Get a tibble of files in the folder
files <- tibble(
  original_path = dir(folder_path, full.names = TRUE),
  original_name = dir(folder_path)
)

files <- files |> 
  inner_join(older_articles, c("original_name" = "filename"))

# Add the new file names based on the `article` index
renamed_files <- files %>%
  mutate(
    # article = paste0("article_", row_number()), # Generate article index
    new_name = paste0(identifier, ".txt"),         # Add desired extension
    new_path = file.path(folder_path, new_name) # Full path for new names
  )

# Rename the files using purrr::walk2
walk2(
  renamed_files$original_path,
  renamed_files$new_path,
  ~ file.rename(.x, .y) # .x = old file path, .y = new file path
)

# Check results
print(renamed_files)
```

### Clean index to join with combined_AI_extracted
```{r}
older_articles <- renamed_files |> 
  mutate(URL = paste0("https://archive.org/details/", identifier, "/")) |> 
  mutate(new_path = str_replace(new_path, "older_articles", "AI_extracted_all")) |> 
  mutate(date = ymd(date)) |> 
  # mutate(date = if_else(year(date) > 1999, date - years(100), date)) |> 
  # mutate(date = as.Date(date, "%Y/%m/%d")) |> 
  mutate(column2 = "NA") |> 
  mutate(page = "NA") |> 
  rename(list = identifier, Year = year, ) |> 
  subset(select = -c(original_path, original_name))

combined_AI_extracted <- combined_AI_extracted |> 
  mutate(date = ymd(date)) |> 
  mutate(volume = NA) |> 
  mutate(issue = NA) |> 
  subset(select = -c(X))

moley_extracted_index <- rbind(combined_AI_extracted, older_articles)

write.csv(moley_extracted_index, ("./AI_extracted_all/moley_extracted_index.csv"))
```

```{r}
moley_extracted_index <- read.csv("./AI_extracted_all/moley_extracted_index.csv")
```



 names(moley_extracted_index)
 [1] "X"        "column2"  "list"     "date"     "Year"     "page"     "URL"      "new_name" "new_path"
[10] "volume"   "issue"  


fix perspective_part_2 for scanning - retry nov 25
```{r}
retry <- read.csv("~/Code/Moley/perspective_part_2/retry_scans_nov_25.csv") |> 
  janitor::clean_names() |> 
   mutate(date = mdy(date_new)) |> 
  mutate(date = if_else(year(date) > 1999, date - years(100), date)) |> 
  mutate(date = as.Date(date, "%Y/%m/%d")) |> 
  filter(scanned=="Y") |> 
    subset(select = -c(date_x, date_y, crap, month, day, month_num, date_new, page1, index, bad_scan, scanned)) |> 
  rename(X = x, Year = year, URL = url)

write.csv(retry, "new_scans.csv")
```


### Sample vs the extracted
```{r}
to_extract <- moley_extracted_index |> 
  anti_join(sample_df, by=c("list"="identifier"))

to_extract <-sample_df |> 
  anti_join( moley_extracted_index, by=c("identifier"="list"))

write.csv(to_extract, "articles_to_extract.csv")

to_extract <- to_extract |> 
    mutate(
    date = str_extract(identifier, "\\d{4}-\\d{2}-\\d{2}"),
    volume = str_extract(identifier, "_\\d+_") %>% str_remove_all("_") %>% as.integer(),
    issue = str_extract(identifier, "_\\d+$") %>% str_remove_all("_") %>% as.integer(),
    year = as.numeric(str_extract(identifier, "19\\d{2}"))
  )
write.csv(to_extract, "articles_to_extract.csv")  

to_1939 <- to_extract |> 
  filter(year < 1939) |> 
  select(identifier) |> 
  as.character()

x_clean <- to_1939


# Split the string into a vector based on ", "
to_1939 <- unlist(strsplit(to_1939, ", "))

to_1939 <- gsub("\\\"", "", to_1939)

head(x_list)


results <- x_list
  

```

# Import combined_AI extracted

```{r}
combined_AI_extracted <- read.csv("./AI_extracted_all/moley_extracted_index.csv") |> 
  mutate(date = ymd(date)) 
```

# Dec 5 Build Index from 57 newly extracted articles

```{r}
folder_path <- "./AI_extracted_all"

new_scans <- list.files("./new_scans/extracted", pattern="*.txt") %>% 
  as.data.frame() |> 
  rename(filename = 1) |> 
  mutate(
    date = str_extract(filename, "\\d{4}-\\d{2}-\\d{2}"),
    volume = str_extract(filename, "_\\d+_") %>% str_remove_all("_") %>% as.integer(),
   issue = str_extract(filename, "_\\d+\\.txt$") %>% str_remove_all("_|\\.txt") %>% as.integer()
  ) |> 
  mutate(date = ymd(date)) |> 
  mutate(Year = year(date)) |> 
  mutate(
    X = NA,
    column2 = NA,
    page = NA) |> 
  mutate(
    list = str_remove_all(filename, ".txt"), 
    URL = paste0("https://archive.org/details/", list, "/"),
    new_path = file.path(folder_path, filename) # Full path for new names
  ) |> 
  rename(new_name = filename)
  
```


### write to moley-extracted-index.all
```{r}

combined_AI_extracted <- rbind(combined_AI_extracted, new_scans)

write.csv(combined_AI_extracted, "./AI_extracted_all/moley_extracted_index.csv")
```

